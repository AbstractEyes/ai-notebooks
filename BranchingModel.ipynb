{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbstractEyes/ai-notebooks/blob/main/BranchingModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8w8C3_U62gF"
      },
      "source": [
        "# The Sequential model\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2020/04/12<br>\n",
        "**Last modified:** 2023/06/25<br>\n",
        "**Description:** Complete guide to the Sequential model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOol_Srv62gF"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = None"
      ],
      "metadata": {
        "id": "NHyS-e52FHy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleCIFAR10DataGenerator(Sequence):\n",
        "    def __init__(self, images, labels, batch_size=32, num_classes=10, shuffle=True):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.images))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_images = self.images[batch_indices]\n",
        "        batch_labels = self.labels[batch_indices]\n",
        "\n",
        "        batch_labels_onehot = to_categorical(batch_labels, num_classes=self.num_classes)\n",
        "        return batch_images, batch_labels_onehot\n",
        "\n",
        "def create_large_model(num_classes=10):\n",
        "    rgb_input = layers.Input(shape=(32, 32, 3), name=\"rgb_input\")\n",
        "\n",
        "    def alpha_output_shape(input_shape):\n",
        "        return (input_shape[0], input_shape[1], input_shape[2], 1)\n",
        "    alpha = layers.Lambda(lambda x: tf.ones_like(x[..., :1]),\n",
        "                          output_shape=alpha_output_shape, name=\"alpha_creation\")(rgb_input)\n",
        "    rgba = layers.Concatenate(axis=-1, name=\"rgba_concat\")([rgb_input, alpha])\n",
        "\n",
        "    def pair_output_shape(input_shape):\n",
        "        return (input_shape[0], input_shape[1], input_shape[2], 2)\n",
        "    def triplet_output_shape(input_shape):\n",
        "        return (input_shape[0], input_shape[1], input_shape[2], 3)\n",
        "\n",
        "    # For pairs that do not reorder channels, direct indexing might still fail, so let's use tf.gather everywhere for consistency:\n",
        "    # rg: [0,1]\n",
        "    rg = layers.Lambda(lambda x: tf.gather(x, [0,1], axis=-1), output_shape=pair_output_shape, name=\"rg_extract\")(rgba)\n",
        "    rb = layers.Lambda(lambda x: tf.gather(x, [0,2], axis=-1), output_shape=pair_output_shape, name=\"rb_extract\")(rgba)\n",
        "    gb = layers.Lambda(lambda x: tf.gather(x, [1,2], axis=-1), output_shape=pair_output_shape, name=\"gb_extract\")(rgba)\n",
        "    ra = layers.Lambda(lambda x: tf.gather(x, [0,3], axis=-1), output_shape=pair_output_shape, name=\"ra_extract\")(rgba)\n",
        "    ga = layers.Lambda(lambda x: tf.gather(x, [1,3], axis=-1), output_shape=pair_output_shape, name=\"ga_extract\")(rgba)\n",
        "    ba = layers.Lambda(lambda x: tf.gather(x, [2,3], axis=-1), output_shape=pair_output_shape, name=\"ba_extract\")(rgba)\n",
        "    rba= layers.Lambda(lambda x: tf.gather(x, [0,2,3], axis=-1), output_shape=triplet_output_shape, name=\"rba_extract\")(rgba)\n",
        "    rga= layers.Lambda(lambda x: tf.gather(x, [0,1,3], axis=-1), output_shape=triplet_output_shape, name=\"rga_extract\")(rgba)\n",
        "    bga= layers.Lambda(lambda x: tf.gather(x, [2,1,3], axis=-1), output_shape=triplet_output_shape, name=\"bga_extract\")(rgba)\n",
        "\n",
        "    # Flatten all\n",
        "    rg_flat = layers.Flatten(name=\"rg_flat\")(rg)\n",
        "    rb_flat = layers.Flatten(name=\"rb_flat\")(rb)\n",
        "    gb_flat = layers.Flatten(name=\"gb_flat\")(gb)\n",
        "    ra_flat = layers.Flatten(name=\"ra_flat\")(ra)\n",
        "    ga_flat = layers.Flatten(name=\"ga_flat\")(ga)\n",
        "    ba_flat = layers.Flatten(name=\"ba_flat\")(ba)\n",
        "    rba_flat= layers.Flatten(name=\"rba_flat\")(rba)\n",
        "    rga_flat= layers.Flatten(name=\"rga_flat\")(rga)\n",
        "    bga_flat= layers.Flatten(name=\"bga_flat\")(bga)\n",
        "\n",
        "    def process_subset(name, input_tensor):\n",
        "        x = layers.Dense(256, activation='relu', name=f\"{name}_dense_1\")(input_tensor)\n",
        "        x = layers.Dense(128, activation='relu', name=f\"{name}_dense_2\")(x)\n",
        "        return x\n",
        "\n",
        "    rg_proc = process_subset(\"rg\", rg_flat)\n",
        "    rb_proc = process_subset(\"rb\", rb_flat)\n",
        "    gb_proc = process_subset(\"gb\", gb_flat)\n",
        "    ra_proc = process_subset(\"ra\", ra_flat)\n",
        "    ga_proc = process_subset(\"ga\", ga_flat)\n",
        "    ba_proc = process_subset(\"ba\", ba_flat)\n",
        "    rba_proc= process_subset(\"rba\", rba_flat)\n",
        "    rga_proc= process_subset(\"rga\", rga_flat)\n",
        "    bga_proc= process_subset(\"bga\", bga_flat)\n",
        "\n",
        "    concatenated = layers.Concatenate(name=\"color_concatenation\")([\n",
        "        rg_proc, rb_proc, gb_proc, ra_proc, ga_proc, ba_proc, rba_proc, rga_proc, bga_proc\n",
        "    ])\n",
        "\n",
        "    x = layers.Dense(512, activation='relu', name=\"final_dense_1\")(concatenated)\n",
        "    x = layers.Dense(256, activation='relu', name=\"final_dense_2\")(x)\n",
        "    output = layers.Dense(num_classes, activation='softmax', name=\"output\")(x)\n",
        "\n",
        "    model = models.Model(inputs=rgb_input, outputs=output)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "yhRANS8vFGZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None"
      ],
      "metadata": {
        "id": "SFgsu-5DFSUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuyWnTho62gG",
        "outputId": "f19660cd-a247-4976-ed8b-5fe49514274e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.8790 - loss: 0.3563 - val_accuracy: 0.9309 - val_loss: 0.1854\n",
            "Epoch 2/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9337 - loss: 0.1940 - val_accuracy: 0.9373 - val_loss: 0.1794\n",
            "Epoch 3/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9293 - loss: 0.2000 - val_accuracy: 0.9285 - val_loss: 0.1994\n",
            "Epoch 4/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9232 - loss: 0.2194 - val_accuracy: 0.9159 - val_loss: 0.2265\n",
            "Epoch 5/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9206 - loss: 0.2259 - val_accuracy: 0.9334 - val_loss: 0.1837\n",
            "Epoch 6/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9347 - loss: 0.1880 - val_accuracy: 0.9289 - val_loss: 0.1934\n",
            "Epoch 7/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9250 - loss: 0.2105 - val_accuracy: 0.9208 - val_loss: 0.2106\n",
            "Epoch 8/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9161 - loss: 0.2362 - val_accuracy: 0.9255 - val_loss: 0.2105\n",
            "Epoch 9/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9264 - loss: 0.2120 - val_accuracy: 0.9325 - val_loss: 0.1831\n",
            "Epoch 10/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9272 - loss: 0.2068 - val_accuracy: 0.9326 - val_loss: 0.1913\n",
            "Epoch 11/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9213 - loss: 0.2289 - val_accuracy: 0.9179 - val_loss: 0.2329\n",
            "Epoch 12/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9147 - loss: 0.2436 - val_accuracy: 0.9248 - val_loss: 0.2125\n",
            "Epoch 13/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9278 - loss: 0.2050 - val_accuracy: 0.9292 - val_loss: 0.2026\n",
            "Epoch 14/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9270 - loss: 0.2121 - val_accuracy: 0.9240 - val_loss: 0.2140\n",
            "Epoch 15/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9241 - loss: 0.2165 - val_accuracy: 0.9347 - val_loss: 0.1892\n",
            "Epoch 16/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9304 - loss: 0.2004 - val_accuracy: 0.9300 - val_loss: 0.1966\n",
            "Epoch 17/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9232 - loss: 0.2165 - val_accuracy: 0.9365 - val_loss: 0.1811\n",
            "Epoch 18/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9324 - loss: 0.1924 - val_accuracy: 0.9253 - val_loss: 0.2058\n",
            "Epoch 19/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9248 - loss: 0.2169 - val_accuracy: 0.9245 - val_loss: 0.2201\n",
            "Epoch 20/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9306 - loss: 0.2026 - val_accuracy: 0.9337 - val_loss: 0.1891\n",
            "Epoch 21/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9367 - loss: 0.1848 - val_accuracy: 0.9358 - val_loss: 0.1766\n",
            "Epoch 22/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9345 - loss: 0.1899 - val_accuracy: 0.9375 - val_loss: 0.1715\n",
            "Epoch 23/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9305 - loss: 0.1959 - val_accuracy: 0.9266 - val_loss: 0.2090\n",
            "Epoch 24/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9227 - loss: 0.2189 - val_accuracy: 0.9343 - val_loss: 0.1897\n",
            "Epoch 25/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9283 - loss: 0.2060 - val_accuracy: 0.9409 - val_loss: 0.1723\n",
            "Epoch 26/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9379 - loss: 0.1818 - val_accuracy: 0.9238 - val_loss: 0.2187\n",
            "Epoch 27/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9279 - loss: 0.2080 - val_accuracy: 0.9405 - val_loss: 0.1693\n",
            "Epoch 28/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9375 - loss: 0.1782 - val_accuracy: 0.9455 - val_loss: 0.1516\n",
            "Epoch 29/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9447 - loss: 0.1574 - val_accuracy: 0.9412 - val_loss: 0.1681\n",
            "Epoch 30/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9416 - loss: 0.1669 - val_accuracy: 0.9307 - val_loss: 0.1874\n",
            "Epoch 31/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9302 - loss: 0.2022 - val_accuracy: 0.9198 - val_loss: 0.2349\n",
            "Epoch 32/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9244 - loss: 0.2214 - val_accuracy: 0.9276 - val_loss: 0.2036\n",
            "Epoch 33/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9266 - loss: 0.2118 - val_accuracy: 0.9306 - val_loss: 0.1919\n",
            "Epoch 34/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9353 - loss: 0.1818 - val_accuracy: 0.9452 - val_loss: 0.1529\n",
            "Epoch 35/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9435 - loss: 0.1623 - val_accuracy: 0.9471 - val_loss: 0.1512\n",
            "Epoch 36/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9409 - loss: 0.1694 - val_accuracy: 0.9302 - val_loss: 0.1919\n",
            "Epoch 37/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9358 - loss: 0.1908 - val_accuracy: 0.9321 - val_loss: 0.1949\n",
            "Epoch 38/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9236 - loss: 0.2241 - val_accuracy: 0.9224 - val_loss: 0.2257\n",
            "Epoch 39/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9317 - loss: 0.1966 - val_accuracy: 0.9422 - val_loss: 0.1624\n",
            "Epoch 40/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9399 - loss: 0.1746 - val_accuracy: 0.9596 - val_loss: 0.1185\n",
            "Epoch 41/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9535 - loss: 0.1326 - val_accuracy: 0.9500 - val_loss: 0.1406\n",
            "Epoch 42/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9454 - loss: 0.1553 - val_accuracy: 0.9449 - val_loss: 0.1526\n",
            "Epoch 43/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9418 - loss: 0.1675 - val_accuracy: 0.9341 - val_loss: 0.1838\n",
            "Epoch 44/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9275 - loss: 0.2140 - val_accuracy: 0.9301 - val_loss: 0.1899\n",
            "Epoch 45/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9293 - loss: 0.2028 - val_accuracy: 0.9355 - val_loss: 0.1809\n",
            "Epoch 46/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9345 - loss: 0.1925 - val_accuracy: 0.9287 - val_loss: 0.1919\n",
            "Epoch 47/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9315 - loss: 0.1973 - val_accuracy: 0.9361 - val_loss: 0.1826\n",
            "Epoch 48/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9237 - loss: 0.2232 - val_accuracy: 0.9328 - val_loss: 0.1952\n",
            "Epoch 49/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9413 - loss: 0.1686 - val_accuracy: 0.9478 - val_loss: 0.1429\n",
            "Epoch 50/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9481 - loss: 0.1479 - val_accuracy: 0.9541 - val_loss: 0.1335\n",
            "Epoch 51/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9531 - loss: 0.1383 - val_accuracy: 0.9573 - val_loss: 0.1243\n",
            "Epoch 52/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9550 - loss: 0.1306 - val_accuracy: 0.9550 - val_loss: 0.1296\n",
            "Epoch 53/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9529 - loss: 0.1349 - val_accuracy: 0.9322 - val_loss: 0.1854\n",
            "Epoch 54/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9425 - loss: 0.1648 - val_accuracy: 0.9393 - val_loss: 0.1716\n",
            "Epoch 55/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9414 - loss: 0.1664 - val_accuracy: 0.9290 - val_loss: 0.2076\n",
            "Epoch 56/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9198 - loss: 0.2384 - val_accuracy: 0.9257 - val_loss: 0.2151\n",
            "Epoch 57/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9231 - loss: 0.2234 - val_accuracy: 0.9284 - val_loss: 0.2108\n",
            "Epoch 58/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9319 - loss: 0.1920 - val_accuracy: 0.9445 - val_loss: 0.1579\n",
            "Epoch 59/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9482 - loss: 0.1478 - val_accuracy: 0.9418 - val_loss: 0.1647\n",
            "Epoch 60/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9407 - loss: 0.1709 - val_accuracy: 0.9379 - val_loss: 0.1699\n",
            "Epoch 61/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9415 - loss: 0.1663 - val_accuracy: 0.9518 - val_loss: 0.1379\n",
            "Epoch 62/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9463 - loss: 0.1541 - val_accuracy: 0.9521 - val_loss: 0.1402\n",
            "Epoch 63/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9482 - loss: 0.1458 - val_accuracy: 0.9584 - val_loss: 0.1205\n",
            "Epoch 64/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9499 - loss: 0.1421 - val_accuracy: 0.9471 - val_loss: 0.1462\n",
            "Epoch 65/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9478 - loss: 0.1486 - val_accuracy: 0.9479 - val_loss: 0.1392\n",
            "Epoch 66/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9488 - loss: 0.1455 - val_accuracy: 0.9487 - val_loss: 0.1531\n",
            "Epoch 67/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9373 - loss: 0.1853 - val_accuracy: 0.9298 - val_loss: 0.2065\n",
            "Epoch 68/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9278 - loss: 0.2108 - val_accuracy: 0.9325 - val_loss: 0.1947\n",
            "Epoch 69/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9274 - loss: 0.2117 - val_accuracy: 0.9349 - val_loss: 0.1808\n",
            "Epoch 70/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9392 - loss: 0.1742 - val_accuracy: 0.9393 - val_loss: 0.1793\n",
            "Epoch 71/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9271 - loss: 0.2189 - val_accuracy: 0.9431 - val_loss: 0.1743\n",
            "Epoch 72/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9373 - loss: 0.1844 - val_accuracy: 0.9423 - val_loss: 0.1775\n",
            "Epoch 73/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9344 - loss: 0.1947 - val_accuracy: 0.9542 - val_loss: 0.1281\n",
            "Epoch 74/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9532 - loss: 0.1347 - val_accuracy: 0.9552 - val_loss: 0.1282\n",
            "Epoch 75/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9591 - loss: 0.1197 - val_accuracy: 0.9636 - val_loss: 0.1078\n",
            "Epoch 76/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9642 - loss: 0.1072 - val_accuracy: 0.9652 - val_loss: 0.0969\n",
            "Epoch 77/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9641 - loss: 0.1032 - val_accuracy: 0.9588 - val_loss: 0.1173\n",
            "Epoch 78/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9603 - loss: 0.1125 - val_accuracy: 0.9633 - val_loss: 0.1067\n",
            "Epoch 79/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9557 - loss: 0.1268 - val_accuracy: 0.9541 - val_loss: 0.1364\n",
            "Epoch 80/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9455 - loss: 0.1569 - val_accuracy: 0.9332 - val_loss: 0.1922\n",
            "Epoch 81/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9232 - loss: 0.2314 - val_accuracy: 0.9106 - val_loss: 0.2772\n",
            "Epoch 82/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9058 - loss: 0.2966 - val_accuracy: 0.9302 - val_loss: 0.2063\n",
            "Epoch 83/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9357 - loss: 0.1887 - val_accuracy: 0.9620 - val_loss: 0.1159\n",
            "Epoch 84/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9559 - loss: 0.1272 - val_accuracy: 0.9544 - val_loss: 0.1272\n",
            "Epoch 85/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9551 - loss: 0.1313 - val_accuracy: 0.9502 - val_loss: 0.1431\n",
            "Epoch 86/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9551 - loss: 0.1298 - val_accuracy: 0.9606 - val_loss: 0.1117\n",
            "Epoch 87/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9589 - loss: 0.1214 - val_accuracy: 0.9523 - val_loss: 0.1385\n",
            "Epoch 88/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9488 - loss: 0.1479 - val_accuracy: 0.9546 - val_loss: 0.1289\n",
            "Epoch 89/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9464 - loss: 0.1562 - val_accuracy: 0.9315 - val_loss: 0.2041\n",
            "Epoch 90/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9365 - loss: 0.1878 - val_accuracy: 0.9425 - val_loss: 0.1602\n",
            "Epoch 91/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9414 - loss: 0.1698 - val_accuracy: 0.9440 - val_loss: 0.1636\n",
            "Epoch 92/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9466 - loss: 0.1555 - val_accuracy: 0.9539 - val_loss: 0.1287\n",
            "Epoch 93/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9510 - loss: 0.1401 - val_accuracy: 0.9557 - val_loss: 0.1297\n",
            "Epoch 94/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9563 - loss: 0.1275 - val_accuracy: 0.9694 - val_loss: 0.0909\n",
            "Epoch 95/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9649 - loss: 0.1021 - val_accuracy: 0.9698 - val_loss: 0.0884\n",
            "Epoch 96/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9641 - loss: 0.1030 - val_accuracy: 0.9666 - val_loss: 0.0945\n",
            "Epoch 97/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9645 - loss: 0.1004 - val_accuracy: 0.9593 - val_loss: 0.1136\n",
            "Epoch 98/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9545 - loss: 0.1315 - val_accuracy: 0.9433 - val_loss: 0.1670\n",
            "Epoch 99/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9426 - loss: 0.1686 - val_accuracy: 0.9365 - val_loss: 0.1809\n",
            "Epoch 100/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9344 - loss: 0.1986 - val_accuracy: 0.9231 - val_loss: 0.2301\n",
            "Epoch 101/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9232 - loss: 0.2351 - val_accuracy: 0.9288 - val_loss: 0.2088\n",
            "Epoch 102/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9253 - loss: 0.2250 - val_accuracy: 0.9488 - val_loss: 0.1478\n",
            "Epoch 103/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9479 - loss: 0.1504 - val_accuracy: 0.9483 - val_loss: 0.1440\n",
            "Epoch 104/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9556 - loss: 0.1300 - val_accuracy: 0.9659 - val_loss: 0.0944\n",
            "Epoch 105/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9604 - loss: 0.1114 - val_accuracy: 0.9602 - val_loss: 0.1124\n",
            "Epoch 106/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9612 - loss: 0.1106 - val_accuracy: 0.9609 - val_loss: 0.1112\n",
            "Epoch 107/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.1121 - val_accuracy: 0.9598 - val_loss: 0.1175\n",
            "Epoch 108/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9461 - loss: 0.1626 - val_accuracy: 0.9429 - val_loss: 0.1640\n",
            "Epoch 109/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9346 - loss: 0.1908 - val_accuracy: 0.9441 - val_loss: 0.1628\n",
            "Epoch 110/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9375 - loss: 0.1822 - val_accuracy: 0.9549 - val_loss: 0.1313\n",
            "Epoch 111/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9550 - loss: 0.1337 - val_accuracy: 0.9564 - val_loss: 0.1237\n",
            "Epoch 112/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9555 - loss: 0.1300 - val_accuracy: 0.9623 - val_loss: 0.1054\n",
            "Epoch 113/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9657 - loss: 0.1020 - val_accuracy: 0.9620 - val_loss: 0.1101\n",
            "Epoch 114/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9659 - loss: 0.0953 - val_accuracy: 0.9644 - val_loss: 0.1046\n",
            "Epoch 115/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9588 - loss: 0.1177 - val_accuracy: 0.9619 - val_loss: 0.1059\n",
            "Epoch 116/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9647 - loss: 0.1032 - val_accuracy: 0.9704 - val_loss: 0.0891\n",
            "Epoch 117/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9550 - loss: 0.1335 - val_accuracy: 0.9304 - val_loss: 0.2144\n",
            "Epoch 118/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9228 - loss: 0.2456 - val_accuracy: 0.9208 - val_loss: 0.2467\n",
            "Epoch 119/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9216 - loss: 0.2420 - val_accuracy: 0.9340 - val_loss: 0.1911\n",
            "Epoch 120/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9409 - loss: 0.1797 - val_accuracy: 0.9311 - val_loss: 0.1965\n",
            "Epoch 121/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9401 - loss: 0.1806 - val_accuracy: 0.9517 - val_loss: 0.1347\n",
            "Epoch 122/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9574 - loss: 0.1263 - val_accuracy: 0.9709 - val_loss: 0.0915\n",
            "Epoch 123/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9668 - loss: 0.0979 - val_accuracy: 0.9680 - val_loss: 0.0926\n",
            "Epoch 124/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9694 - loss: 0.0906 - val_accuracy: 0.9706 - val_loss: 0.0809\n",
            "Epoch 125/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9700 - loss: 0.0879 - val_accuracy: 0.9763 - val_loss: 0.0718\n",
            "Epoch 126/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9691 - loss: 0.0897 - val_accuracy: 0.9596 - val_loss: 0.1137\n",
            "Epoch 127/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9568 - loss: 0.1221 - val_accuracy: 0.9615 - val_loss: 0.1097\n",
            "Epoch 128/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.1068 - val_accuracy: 0.9654 - val_loss: 0.0986\n",
            "Epoch 129/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9595 - loss: 0.1184 - val_accuracy: 0.9516 - val_loss: 0.1465\n",
            "Epoch 130/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9527 - loss: 0.1359 - val_accuracy: 0.9610 - val_loss: 0.1114\n",
            "Epoch 131/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9636 - loss: 0.1049 - val_accuracy: 0.9536 - val_loss: 0.1306\n",
            "Epoch 132/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9488 - loss: 0.1507 - val_accuracy: 0.9493 - val_loss: 0.1441\n",
            "Epoch 133/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9443 - loss: 0.1680 - val_accuracy: 0.9507 - val_loss: 0.1485\n",
            "Epoch 134/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9535 - loss: 0.1384 - val_accuracy: 0.9614 - val_loss: 0.1135\n",
            "Epoch 135/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9566 - loss: 0.1287 - val_accuracy: 0.9585 - val_loss: 0.1191\n",
            "Epoch 136/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9539 - loss: 0.1347 - val_accuracy: 0.9285 - val_loss: 0.2132\n",
            "Epoch 137/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9277 - loss: 0.2194 - val_accuracy: 0.9281 - val_loss: 0.2116\n",
            "Epoch 138/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9393 - loss: 0.1850 - val_accuracy: 0.9502 - val_loss: 0.1436\n",
            "Epoch 139/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9500 - loss: 0.1553 - val_accuracy: 0.9553 - val_loss: 0.1298\n",
            "Epoch 140/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9572 - loss: 0.1263 - val_accuracy: 0.9461 - val_loss: 0.1579\n",
            "Epoch 141/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9578 - loss: 0.1258 - val_accuracy: 0.9668 - val_loss: 0.0977\n",
            "Epoch 142/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9679 - loss: 0.0934 - val_accuracy: 0.9756 - val_loss: 0.0750\n",
            "Epoch 143/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0762 - val_accuracy: 0.9766 - val_loss: 0.0727\n",
            "Epoch 144/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9772 - loss: 0.0668 - val_accuracy: 0.9777 - val_loss: 0.0675\n",
            "Epoch 145/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9724 - loss: 0.0795 - val_accuracy: 0.9647 - val_loss: 0.1027\n",
            "Epoch 146/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9648 - loss: 0.1066 - val_accuracy: 0.9585 - val_loss: 0.1177\n",
            "Epoch 147/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9593 - loss: 0.1216 - val_accuracy: 0.9294 - val_loss: 0.2133\n",
            "Epoch 148/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9188 - loss: 0.2727 - val_accuracy: 0.9105 - val_loss: 0.2863\n",
            "Epoch 149/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9167 - loss: 0.2617 - val_accuracy: 0.9470 - val_loss: 0.1557\n",
            "Epoch 150/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9556 - loss: 0.1298 - val_accuracy: 0.9596 - val_loss: 0.1130\n",
            "Epoch 151/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9620 - loss: 0.1095 - val_accuracy: 0.9727 - val_loss: 0.0822\n",
            "Epoch 152/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9692 - loss: 0.0901 - val_accuracy: 0.9751 - val_loss: 0.0757\n",
            "Epoch 153/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9724 - loss: 0.0816 - val_accuracy: 0.9695 - val_loss: 0.0884\n",
            "Epoch 154/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9691 - loss: 0.0898 - val_accuracy: 0.9666 - val_loss: 0.0993\n",
            "Epoch 155/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9578 - loss: 0.1257 - val_accuracy: 0.9506 - val_loss: 0.1399\n",
            "Epoch 156/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9567 - loss: 0.1282 - val_accuracy: 0.9705 - val_loss: 0.0857\n",
            "Epoch 157/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9559 - loss: 0.1290 - val_accuracy: 0.9563 - val_loss: 0.1366\n",
            "Epoch 158/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9454 - loss: 0.1660 - val_accuracy: 0.9343 - val_loss: 0.1993\n",
            "Epoch 159/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9308 - loss: 0.2197 - val_accuracy: 0.9452 - val_loss: 0.1575\n",
            "Epoch 160/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9442 - loss: 0.1676 - val_accuracy: 0.9599 - val_loss: 0.1148\n",
            "Epoch 161/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9609 - loss: 0.1132 - val_accuracy: 0.9664 - val_loss: 0.0987\n",
            "Epoch 162/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9667 - loss: 0.0974 - val_accuracy: 0.9697 - val_loss: 0.0879\n",
            "Epoch 163/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9709 - loss: 0.0869 - val_accuracy: 0.9745 - val_loss: 0.0767\n",
            "Epoch 164/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9755 - loss: 0.0726 - val_accuracy: 0.9788 - val_loss: 0.0616\n",
            "Epoch 165/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0769 - val_accuracy: 0.9654 - val_loss: 0.0912\n",
            "Epoch 166/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9679 - loss: 0.0932 - val_accuracy: 0.9698 - val_loss: 0.0813\n",
            "Epoch 167/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9672 - loss: 0.0955 - val_accuracy: 0.9683 - val_loss: 0.1036\n",
            "Epoch 168/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9535 - loss: 0.1404 - val_accuracy: 0.9411 - val_loss: 0.1737\n",
            "Epoch 169/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9396 - loss: 0.1881 - val_accuracy: 0.9421 - val_loss: 0.1690\n",
            "Epoch 170/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9364 - loss: 0.1977 - val_accuracy: 0.9351 - val_loss: 0.2025\n",
            "Epoch 171/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9389 - loss: 0.1898 - val_accuracy: 0.9562 - val_loss: 0.1302\n",
            "Epoch 172/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9538 - loss: 0.1354 - val_accuracy: 0.9619 - val_loss: 0.1082\n",
            "Epoch 173/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9650 - loss: 0.1059 - val_accuracy: 0.9767 - val_loss: 0.0726\n",
            "Epoch 174/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9692 - loss: 0.0901 - val_accuracy: 0.9693 - val_loss: 0.0883\n",
            "Epoch 175/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9728 - loss: 0.0831 - val_accuracy: 0.9751 - val_loss: 0.0740\n",
            "Epoch 176/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9763 - loss: 0.0706 - val_accuracy: 0.9747 - val_loss: 0.0750\n",
            "Epoch 177/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9702 - loss: 0.0912 - val_accuracy: 0.9616 - val_loss: 0.1127\n",
            "Epoch 178/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9638 - loss: 0.1063 - val_accuracy: 0.9663 - val_loss: 0.1010\n",
            "Epoch 179/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9635 - loss: 0.1065 - val_accuracy: 0.9699 - val_loss: 0.0931\n",
            "Epoch 180/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9629 - loss: 0.1070 - val_accuracy: 0.9621 - val_loss: 0.1153\n",
            "Epoch 181/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9500 - loss: 0.1530 - val_accuracy: 0.9405 - val_loss: 0.1721\n",
            "Epoch 182/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9338 - loss: 0.2135 - val_accuracy: 0.9501 - val_loss: 0.1445\n",
            "Epoch 183/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9477 - loss: 0.1600 - val_accuracy: 0.9506 - val_loss: 0.1415\n",
            "Epoch 184/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9519 - loss: 0.1437 - val_accuracy: 0.9632 - val_loss: 0.1031\n",
            "Epoch 185/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9552 - loss: 0.1321 - val_accuracy: 0.9601 - val_loss: 0.1115\n",
            "Epoch 186/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9572 - loss: 0.1270 - val_accuracy: 0.9628 - val_loss: 0.1082\n",
            "Epoch 187/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9647 - loss: 0.1049 - val_accuracy: 0.9622 - val_loss: 0.1120\n",
            "Epoch 188/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9660 - loss: 0.0983 - val_accuracy: 0.9750 - val_loss: 0.0744\n",
            "Epoch 189/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9772 - loss: 0.0694 - val_accuracy: 0.9800 - val_loss: 0.0623\n",
            "Epoch 190/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9776 - loss: 0.0658 - val_accuracy: 0.9810 - val_loss: 0.0568\n",
            "Epoch 191/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9831 - loss: 0.0504 - val_accuracy: 0.9821 - val_loss: 0.0548\n",
            "Epoch 192/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9814 - loss: 0.0545 - val_accuracy: 0.9836 - val_loss: 0.0474\n",
            "Epoch 193/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.0523 - val_accuracy: 0.9827 - val_loss: 0.0508\n",
            "Epoch 194/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9809 - loss: 0.0577 - val_accuracy: 0.9700 - val_loss: 0.0855\n",
            "Epoch 195/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9513 - loss: 0.1562 - val_accuracy: 0.9281 - val_loss: 0.2366\n",
            "Epoch 196/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9151 - loss: 0.2916 - val_accuracy: 0.9356 - val_loss: 0.2077\n",
            "Epoch 197/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9265 - loss: 0.2308 - val_accuracy: 0.9448 - val_loss: 0.1676\n",
            "Epoch 198/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9522 - loss: 0.1439 - val_accuracy: 0.9705 - val_loss: 0.0890\n",
            "Epoch 199/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9676 - loss: 0.0979 - val_accuracy: 0.9766 - val_loss: 0.0688\n",
            "Epoch 200/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9764 - loss: 0.0719 - val_accuracy: 0.9759 - val_loss: 0.0731\n",
            "Epoch 201/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9763 - loss: 0.0705 - val_accuracy: 0.9767 - val_loss: 0.0629\n",
            "Epoch 202/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9795 - loss: 0.0642 - val_accuracy: 0.9835 - val_loss: 0.0484\n",
            "Epoch 203/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.0530 - val_accuracy: 0.9837 - val_loss: 0.0447\n",
            "Epoch 204/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9838 - loss: 0.0488 - val_accuracy: 0.9865 - val_loss: 0.0440\n",
            "Epoch 205/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9832 - loss: 0.0509 - val_accuracy: 0.9759 - val_loss: 0.0709\n",
            "Epoch 206/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9691 - loss: 0.0928 - val_accuracy: 0.9559 - val_loss: 0.1321\n",
            "Epoch 207/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9424 - loss: 0.1871 - val_accuracy: 0.9044 - val_loss: 0.3255\n",
            "Epoch 208/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9159 - loss: 0.2690 - val_accuracy: 0.9276 - val_loss: 0.2288\n",
            "Epoch 209/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9300 - loss: 0.2133 - val_accuracy: 0.9418 - val_loss: 0.1813\n",
            "Epoch 210/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9475 - loss: 0.1617 - val_accuracy: 0.9653 - val_loss: 0.1084\n",
            "Epoch 211/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9651 - loss: 0.1026 - val_accuracy: 0.9712 - val_loss: 0.0861\n",
            "Epoch 212/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9728 - loss: 0.0835 - val_accuracy: 0.9811 - val_loss: 0.0575\n",
            "Epoch 213/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9791 - loss: 0.0625 - val_accuracy: 0.9848 - val_loss: 0.0516\n",
            "Epoch 214/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9810 - loss: 0.0602 - val_accuracy: 0.9841 - val_loss: 0.0483\n",
            "Epoch 215/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9797 - loss: 0.0583 - val_accuracy: 0.9795 - val_loss: 0.0614\n",
            "Epoch 216/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9761 - loss: 0.0696 - val_accuracy: 0.9649 - val_loss: 0.0976\n",
            "Epoch 217/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9696 - loss: 0.0919 - val_accuracy: 0.9592 - val_loss: 0.1217\n",
            "Epoch 218/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9498 - loss: 0.1603 - val_accuracy: 0.9482 - val_loss: 0.1611\n",
            "Epoch 219/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9402 - loss: 0.1910 - val_accuracy: 0.9383 - val_loss: 0.1954\n",
            "Epoch 220/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9350 - loss: 0.2077 - val_accuracy: 0.9374 - val_loss: 0.1978\n",
            "Epoch 221/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9316 - loss: 0.2167 - val_accuracy: 0.9511 - val_loss: 0.1539\n",
            "Epoch 222/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9543 - loss: 0.1420 - val_accuracy: 0.9607 - val_loss: 0.1135\n",
            "Epoch 223/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9617 - loss: 0.1128 - val_accuracy: 0.9666 - val_loss: 0.0907\n",
            "Epoch 224/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9704 - loss: 0.0872 - val_accuracy: 0.9773 - val_loss: 0.0656\n",
            "Epoch 225/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9773 - loss: 0.0668 - val_accuracy: 0.9786 - val_loss: 0.0655\n",
            "Epoch 226/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9826 - loss: 0.0533 - val_accuracy: 0.9826 - val_loss: 0.0508\n",
            "Epoch 227/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9816 - loss: 0.0536 - val_accuracy: 0.9876 - val_loss: 0.0412\n",
            "Epoch 228/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0486 - val_accuracy: 0.9839 - val_loss: 0.0451\n",
            "Epoch 229/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9798 - loss: 0.0604 - val_accuracy: 0.9780 - val_loss: 0.0672\n",
            "Epoch 230/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9644 - loss: 0.1046 - val_accuracy: 0.9550 - val_loss: 0.1351\n",
            "Epoch 231/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9481 - loss: 0.1658 - val_accuracy: 0.9409 - val_loss: 0.1945\n",
            "Epoch 232/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9353 - loss: 0.2093 - val_accuracy: 0.9405 - val_loss: 0.2007\n",
            "Epoch 233/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9476 - loss: 0.1585 - val_accuracy: 0.9663 - val_loss: 0.1002\n",
            "Epoch 234/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9643 - loss: 0.1048 - val_accuracy: 0.9722 - val_loss: 0.0792\n",
            "Epoch 235/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9758 - loss: 0.0701 - val_accuracy: 0.9807 - val_loss: 0.0561\n",
            "Epoch 236/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9776 - loss: 0.0649 - val_accuracy: 0.9718 - val_loss: 0.0778\n",
            "Epoch 237/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0660 - val_accuracy: 0.9806 - val_loss: 0.0571\n",
            "Epoch 238/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9816 - loss: 0.0559 - val_accuracy: 0.9833 - val_loss: 0.0486\n",
            "Epoch 239/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0642 - val_accuracy: 0.9742 - val_loss: 0.0742\n",
            "Epoch 240/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9773 - loss: 0.0683 - val_accuracy: 0.9781 - val_loss: 0.0644\n",
            "Epoch 241/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9709 - loss: 0.0862 - val_accuracy: 0.9514 - val_loss: 0.1574\n",
            "Epoch 242/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9425 - loss: 0.1950 - val_accuracy: 0.9050 - val_loss: 0.3334\n",
            "Epoch 243/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9109 - loss: 0.3177 - val_accuracy: 0.9371 - val_loss: 0.2011\n",
            "Epoch 244/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9434 - loss: 0.1770 - val_accuracy: 0.9643 - val_loss: 0.1021\n",
            "Epoch 245/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9676 - loss: 0.0957 - val_accuracy: 0.9707 - val_loss: 0.0820\n",
            "Epoch 246/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9723 - loss: 0.0797 - val_accuracy: 0.9767 - val_loss: 0.0677\n",
            "Epoch 247/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9750 - loss: 0.0764 - val_accuracy: 0.9762 - val_loss: 0.0707\n",
            "Epoch 248/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9721 - loss: 0.0866 - val_accuracy: 0.9718 - val_loss: 0.0861\n",
            "Epoch 249/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9696 - loss: 0.0910 - val_accuracy: 0.9814 - val_loss: 0.0572\n",
            "Epoch 250/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.0813 - val_accuracy: 0.9784 - val_loss: 0.0662\n",
            "Epoch 251/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9736 - loss: 0.0787 - val_accuracy: 0.9709 - val_loss: 0.0860\n",
            "Epoch 252/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9699 - loss: 0.0930 - val_accuracy: 0.9649 - val_loss: 0.1172\n",
            "Epoch 253/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9637 - loss: 0.1140 - val_accuracy: 0.9630 - val_loss: 0.1164\n",
            "Epoch 254/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9481 - loss: 0.1707 - val_accuracy: 0.9445 - val_loss: 0.1733\n",
            "Epoch 255/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9467 - loss: 0.1684 - val_accuracy: 0.9527 - val_loss: 0.1517\n",
            "Epoch 256/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9525 - loss: 0.1513 - val_accuracy: 0.9549 - val_loss: 0.1337\n",
            "Epoch 257/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9511 - loss: 0.1442 - val_accuracy: 0.9665 - val_loss: 0.0967\n",
            "Epoch 258/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9636 - loss: 0.1076 - val_accuracy: 0.9684 - val_loss: 0.0921\n",
            "Epoch 259/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9703 - loss: 0.0874 - val_accuracy: 0.9736 - val_loss: 0.0794\n",
            "Epoch 260/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9767 - loss: 0.0688 - val_accuracy: 0.9804 - val_loss: 0.0596\n",
            "Epoch 261/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9804 - loss: 0.0602 - val_accuracy: 0.9792 - val_loss: 0.0598\n",
            "Epoch 262/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9791 - loss: 0.0598 - val_accuracy: 0.9723 - val_loss: 0.0836\n",
            "Epoch 263/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9750 - loss: 0.0730 - val_accuracy: 0.9707 - val_loss: 0.0900\n",
            "Epoch 264/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9696 - loss: 0.0970 - val_accuracy: 0.9718 - val_loss: 0.0895\n",
            "Epoch 265/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9642 - loss: 0.1060 - val_accuracy: 0.9543 - val_loss: 0.1403\n",
            "Epoch 266/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9563 - loss: 0.1408 - val_accuracy: 0.9632 - val_loss: 0.1172\n",
            "Epoch 267/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9601 - loss: 0.1226 - val_accuracy: 0.9663 - val_loss: 0.1108\n",
            "Epoch 268/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9437 - loss: 0.1860 - val_accuracy: 0.9526 - val_loss: 0.1474\n",
            "Epoch 269/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9536 - loss: 0.1437 - val_accuracy: 0.9591 - val_loss: 0.1208\n",
            "Epoch 270/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9591 - loss: 0.1243 - val_accuracy: 0.9783 - val_loss: 0.0647\n",
            "Epoch 271/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9749 - loss: 0.0741 - val_accuracy: 0.9816 - val_loss: 0.0546\n",
            "Epoch 272/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9776 - loss: 0.0668 - val_accuracy: 0.9794 - val_loss: 0.0634\n",
            "Epoch 273/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9775 - loss: 0.0657 - val_accuracy: 0.9833 - val_loss: 0.0522\n",
            "Epoch 274/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9829 - loss: 0.0521 - val_accuracy: 0.9817 - val_loss: 0.0588\n",
            "Epoch 275/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9803 - loss: 0.0575 - val_accuracy: 0.9773 - val_loss: 0.0631\n",
            "Epoch 276/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9818 - loss: 0.0534 - val_accuracy: 0.9788 - val_loss: 0.0701\n",
            "Epoch 277/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9680 - loss: 0.1000 - val_accuracy: 0.9647 - val_loss: 0.1045\n",
            "Epoch 278/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9496 - loss: 0.1637 - val_accuracy: 0.9571 - val_loss: 0.1382\n",
            "Epoch 279/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9499 - loss: 0.1648 - val_accuracy: 0.9620 - val_loss: 0.1252\n",
            "Epoch 280/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9505 - loss: 0.1527 - val_accuracy: 0.9535 - val_loss: 0.1439\n",
            "Epoch 281/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9541 - loss: 0.1402 - val_accuracy: 0.9663 - val_loss: 0.0982\n",
            "Epoch 282/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9666 - loss: 0.0997 - val_accuracy: 0.9581 - val_loss: 0.1244\n",
            "Epoch 283/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9592 - loss: 0.1256 - val_accuracy: 0.9636 - val_loss: 0.1111\n",
            "Epoch 284/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9635 - loss: 0.1099 - val_accuracy: 0.9751 - val_loss: 0.0742\n",
            "Epoch 285/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9724 - loss: 0.0805 - val_accuracy: 0.9807 - val_loss: 0.0605\n",
            "Epoch 286/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9797 - loss: 0.0622 - val_accuracy: 0.9726 - val_loss: 0.0772\n",
            "Epoch 287/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9734 - loss: 0.0794 - val_accuracy: 0.9762 - val_loss: 0.0656\n",
            "Epoch 288/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9752 - loss: 0.0734 - val_accuracy: 0.9737 - val_loss: 0.0771\n",
            "Epoch 289/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9698 - loss: 0.0943 - val_accuracy: 0.9680 - val_loss: 0.0931\n",
            "Epoch 290/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.0899 - val_accuracy: 0.9737 - val_loss: 0.0766\n",
            "Epoch 291/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9761 - loss: 0.0703 - val_accuracy: 0.9644 - val_loss: 0.1119\n",
            "Epoch 292/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: 0.1075 - val_accuracy: 0.9667 - val_loss: 0.1027\n",
            "Epoch 293/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9623 - loss: 0.1178 - val_accuracy: 0.9612 - val_loss: 0.1212\n",
            "Epoch 294/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9559 - loss: 0.1402 - val_accuracy: 0.9656 - val_loss: 0.1025\n",
            "Epoch 295/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9555 - loss: 0.1496 - val_accuracy: 0.9589 - val_loss: 0.1283\n",
            "Epoch 296/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9617 - loss: 0.1146 - val_accuracy: 0.9690 - val_loss: 0.0960\n",
            "Epoch 297/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9643 - loss: 0.1086 - val_accuracy: 0.9731 - val_loss: 0.0774\n",
            "Epoch 298/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9687 - loss: 0.0962 - val_accuracy: 0.9800 - val_loss: 0.0656\n",
            "Epoch 299/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9759 - loss: 0.0747 - val_accuracy: 0.9829 - val_loss: 0.0496\n",
            "Epoch 300/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9817 - loss: 0.0550 - val_accuracy: 0.9858 - val_loss: 0.0421\n",
            "Epoch 301/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9829 - loss: 0.0511 - val_accuracy: 0.9814 - val_loss: 0.0521\n",
            "Epoch 302/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9809 - loss: 0.0568 - val_accuracy: 0.9780 - val_loss: 0.0657\n",
            "Epoch 303/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9752 - loss: 0.0761 - val_accuracy: 0.9610 - val_loss: 0.1186\n",
            "Epoch 304/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9566 - loss: 0.1384 - val_accuracy: 0.9570 - val_loss: 0.1350\n",
            "Epoch 305/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9585 - loss: 0.1339 - val_accuracy: 0.9539 - val_loss: 0.1426\n",
            "Epoch 306/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9616 - loss: 0.1219 - val_accuracy: 0.9665 - val_loss: 0.1023\n",
            "Epoch 307/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9685 - loss: 0.1003 - val_accuracy: 0.9676 - val_loss: 0.0960\n",
            "Epoch 308/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9688 - loss: 0.0934 - val_accuracy: 0.9782 - val_loss: 0.0669\n",
            "Epoch 309/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9721 - loss: 0.0835 - val_accuracy: 0.9718 - val_loss: 0.0870\n",
            "Epoch 310/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9650 - loss: 0.1053 - val_accuracy: 0.9602 - val_loss: 0.1276\n",
            "Epoch 311/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9656 - loss: 0.1095 - val_accuracy: 0.9764 - val_loss: 0.0778\n",
            "Epoch 312/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9750 - loss: 0.0801 - val_accuracy: 0.9679 - val_loss: 0.1011\n",
            "Epoch 313/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9539 - loss: 0.1502 - val_accuracy: 0.9568 - val_loss: 0.1356\n",
            "Epoch 314/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9491 - loss: 0.1672 - val_accuracy: 0.9621 - val_loss: 0.1169\n",
            "Epoch 315/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9632 - loss: 0.1130 - val_accuracy: 0.9772 - val_loss: 0.0678\n",
            "Epoch 316/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9747 - loss: 0.0784 - val_accuracy: 0.9710 - val_loss: 0.0850\n",
            "Epoch 317/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9755 - loss: 0.0740 - val_accuracy: 0.9695 - val_loss: 0.0914\n",
            "Epoch 318/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9718 - loss: 0.0859 - val_accuracy: 0.9651 - val_loss: 0.1055\n",
            "Epoch 319/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9739 - loss: 0.0806 - val_accuracy: 0.9814 - val_loss: 0.0569\n",
            "Epoch 320/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9719 - loss: 0.0834 - val_accuracy: 0.9631 - val_loss: 0.1117\n",
            "Epoch 321/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9669 - loss: 0.1027 - val_accuracy: 0.9714 - val_loss: 0.0861\n",
            "Epoch 322/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9639 - loss: 0.1143 - val_accuracy: 0.9546 - val_loss: 0.1425\n",
            "Epoch 323/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9600 - loss: 0.1243 - val_accuracy: 0.9726 - val_loss: 0.0869\n",
            "Epoch 324/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9706 - loss: 0.0910 - val_accuracy: 0.9770 - val_loss: 0.0723\n",
            "Epoch 325/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9719 - loss: 0.0843 - val_accuracy: 0.9791 - val_loss: 0.0659\n",
            "Epoch 326/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9734 - loss: 0.0781 - val_accuracy: 0.9689 - val_loss: 0.0929\n",
            "Epoch 327/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9647 - loss: 0.1075 - val_accuracy: 0.9726 - val_loss: 0.0799\n",
            "Epoch 328/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9684 - loss: 0.0982 - val_accuracy: 0.9767 - val_loss: 0.0701\n",
            "Epoch 329/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9737 - loss: 0.0798 - val_accuracy: 0.9774 - val_loss: 0.0662\n",
            "Epoch 330/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9736 - loss: 0.0781 - val_accuracy: 0.9691 - val_loss: 0.1014\n",
            "Epoch 331/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9741 - loss: 0.0830 - val_accuracy: 0.9587 - val_loss: 0.1324\n",
            "Epoch 332/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9546 - loss: 0.1471 - val_accuracy: 0.9503 - val_loss: 0.1701\n",
            "Epoch 333/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9474 - loss: 0.1749 - val_accuracy: 0.9665 - val_loss: 0.1150\n",
            "Epoch 334/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9592 - loss: 0.1317 - val_accuracy: 0.9628 - val_loss: 0.1171\n",
            "Epoch 335/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9705 - loss: 0.0899 - val_accuracy: 0.9809 - val_loss: 0.0566\n",
            "Epoch 336/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9813 - loss: 0.0551 - val_accuracy: 0.9784 - val_loss: 0.0650\n",
            "Epoch 337/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0631 - val_accuracy: 0.9895 - val_loss: 0.0309\n",
            "Epoch 338/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0459 - val_accuracy: 0.9860 - val_loss: 0.0446\n",
            "Epoch 339/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0507 - val_accuracy: 0.9849 - val_loss: 0.0465\n",
            "Epoch 340/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0452 - val_accuracy: 0.9884 - val_loss: 0.0360\n",
            "Epoch 341/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9856 - loss: 0.0452 - val_accuracy: 0.9777 - val_loss: 0.0650\n",
            "Epoch 342/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9670 - loss: 0.1098 - val_accuracy: 0.9506 - val_loss: 0.1594\n",
            "Epoch 343/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9475 - loss: 0.1787 - val_accuracy: 0.9406 - val_loss: 0.1993\n",
            "Epoch 344/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9480 - loss: 0.1711 - val_accuracy: 0.9397 - val_loss: 0.1968\n",
            "Epoch 345/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9521 - loss: 0.1576 - val_accuracy: 0.9596 - val_loss: 0.1234\n",
            "Epoch 346/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9627 - loss: 0.1163 - val_accuracy: 0.9701 - val_loss: 0.0828\n",
            "Epoch 347/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9777 - loss: 0.0668 - val_accuracy: 0.9782 - val_loss: 0.0680\n",
            "Epoch 348/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9777 - loss: 0.0645 - val_accuracy: 0.9828 - val_loss: 0.0502\n",
            "Epoch 349/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0465 - val_accuracy: 0.9815 - val_loss: 0.0583\n",
            "Epoch 350/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9792 - loss: 0.0636 - val_accuracy: 0.9772 - val_loss: 0.0675\n",
            "Epoch 351/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.0944 - val_accuracy: 0.9597 - val_loss: 0.1273\n",
            "Epoch 352/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9560 - loss: 0.1421 - val_accuracy: 0.9671 - val_loss: 0.1004\n",
            "Epoch 353/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9605 - loss: 0.1318 - val_accuracy: 0.9176 - val_loss: 0.3165\n",
            "Epoch 354/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9231 - loss: 0.2741 - val_accuracy: 0.9657 - val_loss: 0.1045\n",
            "Epoch 355/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9633 - loss: 0.1114 - val_accuracy: 0.9804 - val_loss: 0.0591\n",
            "Epoch 356/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9765 - loss: 0.0717 - val_accuracy: 0.9789 - val_loss: 0.0623\n",
            "Epoch 357/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9795 - loss: 0.0658 - val_accuracy: 0.9859 - val_loss: 0.0435\n",
            "Epoch 358/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9840 - loss: 0.0505 - val_accuracy: 0.9864 - val_loss: 0.0396\n",
            "Epoch 359/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9885 - loss: 0.0345 - val_accuracy: 0.9935 - val_loss: 0.0213\n",
            "Epoch 360/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9941 - loss: 0.0202 - val_accuracy: 0.9966 - val_loss: 0.0140\n",
            "Epoch 361/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9948 - loss: 0.0166 - val_accuracy: 0.9956 - val_loss: 0.0157\n",
            "Epoch 362/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9956 - loss: 0.0151 - val_accuracy: 0.9968 - val_loss: 0.0120\n",
            "Epoch 363/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9959 - loss: 0.0149 - val_accuracy: 0.9960 - val_loss: 0.0145\n",
            "Epoch 364/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9952 - loss: 0.0159 - val_accuracy: 0.9959 - val_loss: 0.0164\n",
            "Epoch 365/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9944 - loss: 0.0189 - val_accuracy: 0.9911 - val_loss: 0.0303\n",
            "Epoch 366/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9846 - loss: 0.0440 - val_accuracy: 0.9450 - val_loss: 0.1995\n",
            "Epoch 367/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9281 - loss: 0.2798 - val_accuracy: 0.9217 - val_loss: 0.2610\n",
            "Epoch 368/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9116 - loss: 0.3024 - val_accuracy: 0.9378 - val_loss: 0.2015\n",
            "Epoch 369/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9395 - loss: 0.1939 - val_accuracy: 0.9555 - val_loss: 0.1397\n",
            "Epoch 370/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9602 - loss: 0.1202 - val_accuracy: 0.9681 - val_loss: 0.0967\n",
            "Epoch 371/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9751 - loss: 0.0788 - val_accuracy: 0.9803 - val_loss: 0.0599\n",
            "Epoch 372/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9762 - loss: 0.0735 - val_accuracy: 0.9730 - val_loss: 0.0850\n",
            "Epoch 373/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9627 - loss: 0.1171 - val_accuracy: 0.9730 - val_loss: 0.0846\n",
            "Epoch 374/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9741 - loss: 0.0816 - val_accuracy: 0.9740 - val_loss: 0.0786\n",
            "Epoch 375/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9688 - loss: 0.0944 - val_accuracy: 0.9738 - val_loss: 0.0747\n",
            "Epoch 376/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9754 - loss: 0.0748 - val_accuracy: 0.9823 - val_loss: 0.0575\n",
            "Epoch 377/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9820 - loss: 0.0532 - val_accuracy: 0.9788 - val_loss: 0.0626\n",
            "Epoch 378/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9844 - loss: 0.0490 - val_accuracy: 0.9908 - val_loss: 0.0282\n",
            "Epoch 379/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0240 - val_accuracy: 0.9947 - val_loss: 0.0190\n",
            "Epoch 380/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9937 - loss: 0.0194 - val_accuracy: 0.9962 - val_loss: 0.0151\n",
            "Epoch 381/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9938 - loss: 0.0183 - val_accuracy: 0.9958 - val_loss: 0.0132\n",
            "Epoch 382/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9954 - loss: 0.0150 - val_accuracy: 0.9962 - val_loss: 0.0138\n",
            "Epoch 383/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9954 - loss: 0.0154 - val_accuracy: 0.9947 - val_loss: 0.0162\n",
            "Epoch 384/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9906 - loss: 0.0294 - val_accuracy: 0.9668 - val_loss: 0.1048\n",
            "Epoch 385/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9621 - loss: 0.1319 - val_accuracy: 0.9203 - val_loss: 0.3227\n",
            "Epoch 386/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9107 - loss: 0.3424 - val_accuracy: 0.9186 - val_loss: 0.2604\n",
            "Epoch 387/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9284 - loss: 0.2395 - val_accuracy: 0.9601 - val_loss: 0.1166\n",
            "Epoch 388/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9627 - loss: 0.1162 - val_accuracy: 0.9596 - val_loss: 0.1200\n",
            "Epoch 389/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9668 - loss: 0.1009 - val_accuracy: 0.9652 - val_loss: 0.1077\n",
            "Epoch 390/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9662 - loss: 0.1043 - val_accuracy: 0.9737 - val_loss: 0.0824\n",
            "Epoch 391/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9649 - loss: 0.1140 - val_accuracy: 0.9659 - val_loss: 0.1130\n",
            "Epoch 392/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9616 - loss: 0.1198 - val_accuracy: 0.9775 - val_loss: 0.0656\n",
            "Epoch 393/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9782 - loss: 0.0663 - val_accuracy: 0.9884 - val_loss: 0.0386\n",
            "Epoch 394/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9887 - loss: 0.0347 - val_accuracy: 0.9901 - val_loss: 0.0283\n",
            "Epoch 395/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0302 - val_accuracy: 0.9906 - val_loss: 0.0283\n",
            "Epoch 396/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0314 - val_accuracy: 0.9886 - val_loss: 0.0347\n",
            "Epoch 397/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0274 - val_accuracy: 0.9944 - val_loss: 0.0175\n",
            "Epoch 398/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0232 - val_accuracy: 0.9922 - val_loss: 0.0224\n",
            "Epoch 399/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0327 - val_accuracy: 0.9831 - val_loss: 0.0522\n",
            "Epoch 400/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9766 - loss: 0.0724 - val_accuracy: 0.9512 - val_loss: 0.1689\n",
            "Epoch 401/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9364 - loss: 0.2335 - val_accuracy: 0.9361 - val_loss: 0.2148\n",
            "Epoch 402/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9364 - loss: 0.2190 - val_accuracy: 0.9400 - val_loss: 0.1884\n",
            "Epoch 403/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9498 - loss: 0.1643 - val_accuracy: 0.9637 - val_loss: 0.1100\n",
            "Epoch 404/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9551 - loss: 0.1458 - val_accuracy: 0.9613 - val_loss: 0.1144\n",
            "Epoch 405/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9601 - loss: 0.1191 - val_accuracy: 0.9723 - val_loss: 0.0864\n",
            "Epoch 406/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9744 - loss: 0.0794 - val_accuracy: 0.9832 - val_loss: 0.0525\n",
            "Epoch 407/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9802 - loss: 0.0616 - val_accuracy: 0.9829 - val_loss: 0.0520\n",
            "Epoch 408/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9834 - loss: 0.0505 - val_accuracy: 0.9884 - val_loss: 0.0390\n",
            "Epoch 409/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0391 - val_accuracy: 0.9915 - val_loss: 0.0258\n",
            "Epoch 410/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0233 - val_accuracy: 0.9936 - val_loss: 0.0212\n",
            "Epoch 411/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.0219 - val_accuracy: 0.9954 - val_loss: 0.0176\n",
            "Epoch 412/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0240 - val_accuracy: 0.9855 - val_loss: 0.0431\n",
            "Epoch 413/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9856 - loss: 0.0452 - val_accuracy: 0.9899 - val_loss: 0.0315\n",
            "Epoch 414/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9832 - loss: 0.0503 - val_accuracy: 0.9710 - val_loss: 0.0888\n",
            "Epoch 415/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9479 - loss: 0.1940 - val_accuracy: 0.9277 - val_loss: 0.2534\n",
            "Epoch 416/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9330 - loss: 0.2342 - val_accuracy: 0.9440 - val_loss: 0.1754\n",
            "Epoch 417/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9555 - loss: 0.1453 - val_accuracy: 0.9549 - val_loss: 0.1513\n",
            "Epoch 418/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9539 - loss: 0.1452 - val_accuracy: 0.9714 - val_loss: 0.0844\n",
            "Epoch 419/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9738 - loss: 0.0808 - val_accuracy: 0.9792 - val_loss: 0.0693\n",
            "Epoch 420/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9788 - loss: 0.0644 - val_accuracy: 0.9867 - val_loss: 0.0383\n",
            "Epoch 421/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9846 - loss: 0.0480 - val_accuracy: 0.9881 - val_loss: 0.0349\n",
            "Epoch 422/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9851 - loss: 0.0477 - val_accuracy: 0.9883 - val_loss: 0.0372\n",
            "Epoch 423/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0379 - val_accuracy: 0.9921 - val_loss: 0.0231\n",
            "Epoch 424/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0282 - val_accuracy: 0.9917 - val_loss: 0.0258\n",
            "Epoch 425/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0335 - val_accuracy: 0.9869 - val_loss: 0.0388\n",
            "Epoch 426/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0506 - val_accuracy: 0.9780 - val_loss: 0.0708\n",
            "Epoch 427/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9684 - loss: 0.1029 - val_accuracy: 0.9270 - val_loss: 0.2703\n",
            "Epoch 428/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9282 - loss: 0.2716 - val_accuracy: 0.9276 - val_loss: 0.2300\n",
            "Epoch 429/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9381 - loss: 0.2087 - val_accuracy: 0.9643 - val_loss: 0.1122\n",
            "Epoch 430/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9648 - loss: 0.1098 - val_accuracy: 0.9672 - val_loss: 0.1019\n",
            "Epoch 431/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9752 - loss: 0.0733 - val_accuracy: 0.9872 - val_loss: 0.0395\n",
            "Epoch 432/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0471 - val_accuracy: 0.9863 - val_loss: 0.0385\n",
            "Epoch 433/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9853 - loss: 0.0475 - val_accuracy: 0.9795 - val_loss: 0.0604\n",
            "Epoch 434/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9759 - loss: 0.0719 - val_accuracy: 0.9806 - val_loss: 0.0603\n",
            "Epoch 435/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9786 - loss: 0.0653 - val_accuracy: 0.9823 - val_loss: 0.0575\n",
            "Epoch 436/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9716 - loss: 0.0940 - val_accuracy: 0.9730 - val_loss: 0.0862\n",
            "Epoch 437/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9716 - loss: 0.0925 - val_accuracy: 0.9694 - val_loss: 0.0990\n",
            "Epoch 438/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9682 - loss: 0.1037 - val_accuracy: 0.9649 - val_loss: 0.1065\n",
            "Epoch 439/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9657 - loss: 0.1136 - val_accuracy: 0.9643 - val_loss: 0.1128\n",
            "Epoch 440/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9710 - loss: 0.0904 - val_accuracy: 0.9674 - val_loss: 0.1143\n",
            "Epoch 441/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9655 - loss: 0.1123 - val_accuracy: 0.9678 - val_loss: 0.1000\n",
            "Epoch 442/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9728 - loss: 0.0835 - val_accuracy: 0.9765 - val_loss: 0.0746\n",
            "Epoch 443/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9820 - loss: 0.0521 - val_accuracy: 0.9891 - val_loss: 0.0348\n",
            "Epoch 444/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.0430 - val_accuracy: 0.9863 - val_loss: 0.0426\n",
            "Epoch 445/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9882 - loss: 0.0375 - val_accuracy: 0.9868 - val_loss: 0.0408\n",
            "Epoch 446/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9835 - loss: 0.0513 - val_accuracy: 0.9770 - val_loss: 0.0707\n",
            "Epoch 447/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9717 - loss: 0.0899 - val_accuracy: 0.9736 - val_loss: 0.0860\n",
            "Epoch 448/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9758 - loss: 0.0738 - val_accuracy: 0.9708 - val_loss: 0.0899\n",
            "Epoch 449/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9680 - loss: 0.1007 - val_accuracy: 0.9559 - val_loss: 0.1432\n",
            "Epoch 450/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9588 - loss: 0.1374 - val_accuracy: 0.9564 - val_loss: 0.1519\n",
            "Epoch 451/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9477 - loss: 0.1807 - val_accuracy: 0.9612 - val_loss: 0.1277\n",
            "Epoch 452/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9501 - loss: 0.1745 - val_accuracy: 0.9732 - val_loss: 0.0924\n",
            "Epoch 453/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9630 - loss: 0.1176 - val_accuracy: 0.9772 - val_loss: 0.0721\n",
            "Epoch 454/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9755 - loss: 0.0744 - val_accuracy: 0.9836 - val_loss: 0.0489\n",
            "Epoch 455/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0504 - val_accuracy: 0.9866 - val_loss: 0.0380\n",
            "Epoch 456/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9891 - loss: 0.0348 - val_accuracy: 0.9890 - val_loss: 0.0339\n",
            "Epoch 457/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0273 - val_accuracy: 0.9964 - val_loss: 0.0147\n",
            "Epoch 458/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9948 - loss: 0.0182 - val_accuracy: 0.9915 - val_loss: 0.0238\n",
            "Epoch 459/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0234 - val_accuracy: 0.9956 - val_loss: 0.0169\n",
            "Epoch 460/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9942 - loss: 0.0185 - val_accuracy: 0.9946 - val_loss: 0.0184\n",
            "Epoch 461/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9906 - loss: 0.0280 - val_accuracy: 0.9854 - val_loss: 0.0430\n",
            "Epoch 462/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9813 - loss: 0.0583 - val_accuracy: 0.9664 - val_loss: 0.1136\n",
            "Epoch 463/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9495 - loss: 0.1878 - val_accuracy: 0.9353 - val_loss: 0.2356\n",
            "Epoch 464/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9433 - loss: 0.1998 - val_accuracy: 0.9646 - val_loss: 0.1069\n",
            "Epoch 465/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9588 - loss: 0.1328 - val_accuracy: 0.9671 - val_loss: 0.1061\n",
            "Epoch 466/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9646 - loss: 0.1114 - val_accuracy: 0.9814 - val_loss: 0.0569\n",
            "Epoch 467/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9643 - loss: 0.1148 - val_accuracy: 0.9671 - val_loss: 0.1055\n",
            "Epoch 468/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9639 - loss: 0.1132 - val_accuracy: 0.9642 - val_loss: 0.1063\n",
            "Epoch 469/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9641 - loss: 0.1169 - val_accuracy: 0.9716 - val_loss: 0.0806\n",
            "Epoch 470/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0691 - val_accuracy: 0.9835 - val_loss: 0.0528\n",
            "Epoch 471/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9842 - loss: 0.0497 - val_accuracy: 0.9910 - val_loss: 0.0292\n",
            "Epoch 472/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9889 - loss: 0.0369 - val_accuracy: 0.9903 - val_loss: 0.0280\n",
            "Epoch 473/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9869 - loss: 0.0419 - val_accuracy: 0.9768 - val_loss: 0.0751\n",
            "Epoch 474/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9797 - loss: 0.0647 - val_accuracy: 0.9676 - val_loss: 0.1036\n",
            "Epoch 475/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9708 - loss: 0.0914 - val_accuracy: 0.9670 - val_loss: 0.1132\n",
            "Epoch 476/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9556 - loss: 0.1573 - val_accuracy: 0.9672 - val_loss: 0.1135\n",
            "Epoch 477/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9672 - loss: 0.1035 - val_accuracy: 0.9406 - val_loss: 0.2153\n",
            "Epoch 478/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9597 - loss: 0.1320 - val_accuracy: 0.9727 - val_loss: 0.0840\n",
            "Epoch 479/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9772 - loss: 0.0705 - val_accuracy: 0.9723 - val_loss: 0.0905\n",
            "Epoch 480/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9731 - loss: 0.0821 - val_accuracy: 0.9882 - val_loss: 0.0360\n",
            "Epoch 481/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9842 - loss: 0.0470 - val_accuracy: 0.9874 - val_loss: 0.0368\n",
            "Epoch 482/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0515 - val_accuracy: 0.9799 - val_loss: 0.0647\n",
            "Epoch 483/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9729 - loss: 0.0862 - val_accuracy: 0.9664 - val_loss: 0.1053\n",
            "Epoch 484/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9670 - loss: 0.1072 - val_accuracy: 0.9715 - val_loss: 0.0949\n",
            "Epoch 485/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9710 - loss: 0.0996 - val_accuracy: 0.9700 - val_loss: 0.1042\n",
            "Epoch 486/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9746 - loss: 0.0814 - val_accuracy: 0.9818 - val_loss: 0.0559\n",
            "Epoch 487/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9767 - loss: 0.0712 - val_accuracy: 0.9578 - val_loss: 0.1389\n",
            "Epoch 488/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9660 - loss: 0.1114 - val_accuracy: 0.9631 - val_loss: 0.1205\n",
            "Epoch 489/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9638 - loss: 0.1217 - val_accuracy: 0.9658 - val_loss: 0.1153\n",
            "Epoch 490/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: 0.1201 - val_accuracy: 0.9675 - val_loss: 0.0973\n",
            "Epoch 491/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9719 - loss: 0.0930 - val_accuracy: 0.9735 - val_loss: 0.0805\n",
            "Epoch 492/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9724 - loss: 0.0874 - val_accuracy: 0.9855 - val_loss: 0.0484\n",
            "Epoch 493/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0586 - val_accuracy: 0.9845 - val_loss: 0.0487\n",
            "Epoch 494/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9837 - loss: 0.0486 - val_accuracy: 0.9825 - val_loss: 0.0490\n",
            "Epoch 495/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9819 - loss: 0.0556 - val_accuracy: 0.9770 - val_loss: 0.0712\n",
            "Epoch 496/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9798 - loss: 0.0631 - val_accuracy: 0.9814 - val_loss: 0.0583\n",
            "Epoch 497/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9838 - loss: 0.0490 - val_accuracy: 0.9787 - val_loss: 0.0619\n",
            "Epoch 498/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9760 - loss: 0.0740 - val_accuracy: 0.9848 - val_loss: 0.0558\n",
            "Epoch 499/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9775 - loss: 0.0704 - val_accuracy: 0.9785 - val_loss: 0.0719\n",
            "Epoch 500/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9693 - loss: 0.1018 - val_accuracy: 0.9546 - val_loss: 0.1584\n",
            "Epoch 501/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9526 - loss: 0.1698 - val_accuracy: 0.9575 - val_loss: 0.1385\n",
            "Epoch 502/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9563 - loss: 0.1478 - val_accuracy: 0.9623 - val_loss: 0.1290\n",
            "Epoch 503/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9596 - loss: 0.1324 - val_accuracy: 0.9778 - val_loss: 0.0645\n",
            "Epoch 504/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9786 - loss: 0.0685 - val_accuracy: 0.9781 - val_loss: 0.0654\n",
            "Epoch 505/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9777 - loss: 0.0668 - val_accuracy: 0.9797 - val_loss: 0.0573\n",
            "Epoch 506/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9782 - loss: 0.0693 - val_accuracy: 0.9787 - val_loss: 0.0648\n",
            "Epoch 507/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9785 - loss: 0.0660 - val_accuracy: 0.9876 - val_loss: 0.0382\n",
            "Epoch 508/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.0449 - val_accuracy: 0.9915 - val_loss: 0.0269\n",
            "Epoch 509/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0442 - val_accuracy: 0.9875 - val_loss: 0.0385\n",
            "Epoch 510/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9855 - loss: 0.0429 - val_accuracy: 0.9891 - val_loss: 0.0314\n",
            "Epoch 511/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9879 - loss: 0.0364 - val_accuracy: 0.9717 - val_loss: 0.0951\n",
            "Epoch 512/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9673 - loss: 0.1113 - val_accuracy: 0.9557 - val_loss: 0.1496\n",
            "Epoch 513/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9562 - loss: 0.1498 - val_accuracy: 0.9673 - val_loss: 0.0949\n",
            "Epoch 514/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9624 - loss: 0.1219 - val_accuracy: 0.9676 - val_loss: 0.1013\n",
            "Epoch 515/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9648 - loss: 0.1189 - val_accuracy: 0.9716 - val_loss: 0.0878\n",
            "Epoch 516/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9706 - loss: 0.0995 - val_accuracy: 0.9759 - val_loss: 0.0814\n",
            "Epoch 517/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9715 - loss: 0.0895 - val_accuracy: 0.9761 - val_loss: 0.0729\n",
            "Epoch 518/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9782 - loss: 0.0695 - val_accuracy: 0.9869 - val_loss: 0.0400\n",
            "Epoch 519/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0410 - val_accuracy: 0.9871 - val_loss: 0.0402\n",
            "Epoch 520/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9825 - loss: 0.0562 - val_accuracy: 0.9843 - val_loss: 0.0472\n",
            "Epoch 521/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9796 - loss: 0.0630 - val_accuracy: 0.9793 - val_loss: 0.0651\n",
            "Epoch 522/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9736 - loss: 0.0858 - val_accuracy: 0.9691 - val_loss: 0.0934\n",
            "Epoch 523/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9760 - loss: 0.0761 - val_accuracy: 0.9727 - val_loss: 0.0809\n",
            "Epoch 524/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9718 - loss: 0.0922 - val_accuracy: 0.9823 - val_loss: 0.0550\n",
            "Epoch 525/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9706 - loss: 0.0991 - val_accuracy: 0.9724 - val_loss: 0.0961\n",
            "Epoch 526/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9614 - loss: 0.1316 - val_accuracy: 0.9743 - val_loss: 0.0853\n",
            "Epoch 527/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9634 - loss: 0.1328 - val_accuracy: 0.9610 - val_loss: 0.1259\n",
            "Epoch 528/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9650 - loss: 0.1196 - val_accuracy: 0.9679 - val_loss: 0.1091\n",
            "Epoch 529/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9653 - loss: 0.1133 - val_accuracy: 0.9687 - val_loss: 0.0948\n",
            "Epoch 530/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9773 - loss: 0.0729 - val_accuracy: 0.9825 - val_loss: 0.0527\n",
            "Epoch 531/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9813 - loss: 0.0606 - val_accuracy: 0.9903 - val_loss: 0.0305\n",
            "Epoch 532/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0410 - val_accuracy: 0.9905 - val_loss: 0.0280\n",
            "Epoch 533/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0296 - val_accuracy: 0.9915 - val_loss: 0.0248\n",
            "Epoch 534/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0241 - val_accuracy: 0.9906 - val_loss: 0.0303\n",
            "Epoch 535/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0319 - val_accuracy: 0.9707 - val_loss: 0.1002\n",
            "Epoch 536/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: 0.1204 - val_accuracy: 0.9311 - val_loss: 0.2698\n",
            "Epoch 537/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9397 - loss: 0.2231 - val_accuracy: 0.9496 - val_loss: 0.1741\n",
            "Epoch 538/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9610 - loss: 0.1318 - val_accuracy: 0.9547 - val_loss: 0.1513\n",
            "Epoch 539/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9667 - loss: 0.1077 - val_accuracy: 0.9753 - val_loss: 0.0730\n",
            "Epoch 540/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9761 - loss: 0.0751 - val_accuracy: 0.9801 - val_loss: 0.0559\n",
            "Epoch 541/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9828 - loss: 0.0508 - val_accuracy: 0.9881 - val_loss: 0.0365\n",
            "Epoch 542/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9859 - loss: 0.0442 - val_accuracy: 0.9926 - val_loss: 0.0244\n",
            "Epoch 543/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9875 - loss: 0.0376 - val_accuracy: 0.9942 - val_loss: 0.0195\n",
            "Epoch 544/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9877 - loss: 0.0388 - val_accuracy: 0.9818 - val_loss: 0.0595\n",
            "Epoch 545/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9818 - loss: 0.0581 - val_accuracy: 0.9771 - val_loss: 0.0700\n",
            "Epoch 546/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9666 - loss: 0.1194 - val_accuracy: 0.9427 - val_loss: 0.2005\n",
            "Epoch 547/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9496 - loss: 0.1817 - val_accuracy: 0.9402 - val_loss: 0.2066\n",
            "Epoch 548/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9455 - loss: 0.1937 - val_accuracy: 0.9528 - val_loss: 0.1665\n",
            "Epoch 549/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9658 - loss: 0.1096 - val_accuracy: 0.9763 - val_loss: 0.0709\n",
            "Epoch 550/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9779 - loss: 0.0681 - val_accuracy: 0.9914 - val_loss: 0.0294\n",
            "Epoch 551/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0279 - val_accuracy: 0.9951 - val_loss: 0.0157\n",
            "Epoch 552/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9929 - loss: 0.0227 - val_accuracy: 0.9956 - val_loss: 0.0162\n",
            "Epoch 553/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9942 - loss: 0.0190 - val_accuracy: 0.9968 - val_loss: 0.0126\n",
            "Epoch 554/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9949 - loss: 0.0159 - val_accuracy: 0.9955 - val_loss: 0.0144\n",
            "Epoch 555/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9960 - loss: 0.0136 - val_accuracy: 0.9965 - val_loss: 0.0123\n",
            "Epoch 556/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9972 - loss: 0.0110 - val_accuracy: 0.9974 - val_loss: 0.0093\n",
            "Epoch 557/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9967 - loss: 0.0118 - val_accuracy: 0.9932 - val_loss: 0.0192\n",
            "Epoch 558/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0252 - val_accuracy: 0.9952 - val_loss: 0.0169\n",
            "Epoch 559/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9895 - loss: 0.0317 - val_accuracy: 0.9870 - val_loss: 0.0428\n",
            "Epoch 560/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9745 - loss: 0.0894 - val_accuracy: 0.9463 - val_loss: 0.2111\n",
            "Epoch 561/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9363 - loss: 0.2535 - val_accuracy: 0.9399 - val_loss: 0.2026\n",
            "Epoch 562/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9407 - loss: 0.2128 - val_accuracy: 0.9649 - val_loss: 0.1148\n",
            "Epoch 563/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9639 - loss: 0.1186 - val_accuracy: 0.9616 - val_loss: 0.1272\n",
            "Epoch 564/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9579 - loss: 0.1391 - val_accuracy: 0.9597 - val_loss: 0.1389\n",
            "Epoch 565/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9628 - loss: 0.1222 - val_accuracy: 0.9822 - val_loss: 0.0557\n",
            "Epoch 566/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9810 - loss: 0.0592 - val_accuracy: 0.9830 - val_loss: 0.0543\n",
            "Epoch 567/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0449 - val_accuracy: 0.9858 - val_loss: 0.0396\n",
            "Epoch 568/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9827 - loss: 0.0570 - val_accuracy: 0.9766 - val_loss: 0.0690\n",
            "Epoch 569/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9750 - loss: 0.0812 - val_accuracy: 0.9681 - val_loss: 0.1039\n",
            "Epoch 570/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9727 - loss: 0.0882 - val_accuracy: 0.9789 - val_loss: 0.0676\n",
            "Epoch 571/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9733 - loss: 0.0829 - val_accuracy: 0.9715 - val_loss: 0.0886\n",
            "Epoch 572/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9735 - loss: 0.0882 - val_accuracy: 0.9803 - val_loss: 0.0617\n",
            "Epoch 573/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9817 - loss: 0.0564 - val_accuracy: 0.9863 - val_loss: 0.0461\n",
            "Epoch 574/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9833 - loss: 0.0514 - val_accuracy: 0.9825 - val_loss: 0.0596\n",
            "Epoch 575/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9776 - loss: 0.0709 - val_accuracy: 0.9683 - val_loss: 0.1068\n",
            "Epoch 576/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9615 - loss: 0.1434 - val_accuracy: 0.9496 - val_loss: 0.1890\n",
            "Epoch 577/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9538 - loss: 0.1671 - val_accuracy: 0.9639 - val_loss: 0.1257\n",
            "Epoch 578/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9596 - loss: 0.1380 - val_accuracy: 0.9673 - val_loss: 0.1039\n",
            "Epoch 579/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9635 - loss: 0.1139 - val_accuracy: 0.9803 - val_loss: 0.0620\n",
            "Epoch 580/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9775 - loss: 0.0719 - val_accuracy: 0.9875 - val_loss: 0.0332\n",
            "Epoch 581/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9861 - loss: 0.0422 - val_accuracy: 0.9686 - val_loss: 0.1060\n",
            "Epoch 582/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9747 - loss: 0.0858 - val_accuracy: 0.9766 - val_loss: 0.0744\n",
            "Epoch 583/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9763 - loss: 0.0779 - val_accuracy: 0.9795 - val_loss: 0.0585\n",
            "Epoch 584/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9835 - loss: 0.0532 - val_accuracy: 0.9812 - val_loss: 0.0579\n",
            "Epoch 585/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9755 - loss: 0.0808 - val_accuracy: 0.9752 - val_loss: 0.0836\n",
            "Epoch 586/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9816 - loss: 0.0573 - val_accuracy: 0.9896 - val_loss: 0.0372\n",
            "Epoch 587/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9887 - loss: 0.0360 - val_accuracy: 0.9857 - val_loss: 0.0459\n",
            "Epoch 588/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9867 - loss: 0.0402 - val_accuracy: 0.9913 - val_loss: 0.0285\n",
            "Epoch 589/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0309 - val_accuracy: 0.9919 - val_loss: 0.0300\n",
            "Epoch 590/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9878 - loss: 0.0369 - val_accuracy: 0.9784 - val_loss: 0.0727\n",
            "Epoch 591/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9739 - loss: 0.0887 - val_accuracy: 0.9561 - val_loss: 0.1468\n",
            "Epoch 592/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9641 - loss: 0.1220 - val_accuracy: 0.9720 - val_loss: 0.0932\n",
            "Epoch 593/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9691 - loss: 0.1031 - val_accuracy: 0.9665 - val_loss: 0.1123\n",
            "Epoch 594/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9608 - loss: 0.1340 - val_accuracy: 0.9649 - val_loss: 0.1149\n",
            "Epoch 595/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9650 - loss: 0.1136 - val_accuracy: 0.9818 - val_loss: 0.0572\n",
            "Epoch 596/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9771 - loss: 0.0738 - val_accuracy: 0.9685 - val_loss: 0.1086\n",
            "Epoch 597/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9680 - loss: 0.1035 - val_accuracy: 0.9734 - val_loss: 0.0842\n",
            "Epoch 598/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9656 - loss: 0.1247 - val_accuracy: 0.9681 - val_loss: 0.1090\n",
            "Epoch 599/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9647 - loss: 0.1226 - val_accuracy: 0.9798 - val_loss: 0.0694\n",
            "Epoch 600/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9737 - loss: 0.0877 - val_accuracy: 0.9866 - val_loss: 0.0431\n",
            "Epoch 601/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0600 - val_accuracy: 0.9858 - val_loss: 0.0429\n",
            "Epoch 602/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0473 - val_accuracy: 0.9824 - val_loss: 0.0524\n",
            "Epoch 603/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9848 - loss: 0.0471 - val_accuracy: 0.9826 - val_loss: 0.0576\n",
            "Epoch 604/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9840 - loss: 0.0498 - val_accuracy: 0.9883 - val_loss: 0.0334\n",
            "Epoch 605/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0499 - val_accuracy: 0.9824 - val_loss: 0.0569\n",
            "Epoch 606/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9835 - loss: 0.0560 - val_accuracy: 0.9865 - val_loss: 0.0437\n",
            "Epoch 607/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.0565 - val_accuracy: 0.9855 - val_loss: 0.0442\n",
            "Epoch 608/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9761 - loss: 0.0810 - val_accuracy: 0.9748 - val_loss: 0.0799\n",
            "Epoch 609/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9693 - loss: 0.1132 - val_accuracy: 0.9674 - val_loss: 0.1186\n",
            "Epoch 610/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9614 - loss: 0.1353 - val_accuracy: 0.9344 - val_loss: 0.2647\n",
            "Epoch 611/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9499 - loss: 0.1844 - val_accuracy: 0.9701 - val_loss: 0.0972\n",
            "Epoch 612/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9750 - loss: 0.0815 - val_accuracy: 0.9811 - val_loss: 0.0604\n",
            "Epoch 613/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9813 - loss: 0.0576 - val_accuracy: 0.9837 - val_loss: 0.0466\n",
            "Epoch 614/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9841 - loss: 0.0513 - val_accuracy: 0.9868 - val_loss: 0.0445\n",
            "Epoch 615/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9846 - loss: 0.0475 - val_accuracy: 0.9837 - val_loss: 0.0583\n",
            "Epoch 616/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9815 - loss: 0.0603 - val_accuracy: 0.9721 - val_loss: 0.0941\n",
            "Epoch 617/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9769 - loss: 0.0760 - val_accuracy: 0.9819 - val_loss: 0.0572\n",
            "Epoch 618/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9790 - loss: 0.0698 - val_accuracy: 0.9761 - val_loss: 0.0745\n",
            "Epoch 619/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9744 - loss: 0.0885 - val_accuracy: 0.9589 - val_loss: 0.1431\n",
            "Epoch 620/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9667 - loss: 0.1163 - val_accuracy: 0.9791 - val_loss: 0.0673\n",
            "Epoch 621/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0702 - val_accuracy: 0.9691 - val_loss: 0.1030\n",
            "Epoch 622/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9728 - loss: 0.0872 - val_accuracy: 0.9825 - val_loss: 0.0534\n",
            "Epoch 623/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9839 - loss: 0.0497 - val_accuracy: 0.9772 - val_loss: 0.0700\n",
            "Epoch 624/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9795 - loss: 0.0670 - val_accuracy: 0.9707 - val_loss: 0.0980\n",
            "Epoch 625/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: 0.1312 - val_accuracy: 0.9525 - val_loss: 0.1675\n",
            "Epoch 626/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9660 - loss: 0.1207 - val_accuracy: 0.9799 - val_loss: 0.0631\n",
            "Epoch 627/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9742 - loss: 0.0851 - val_accuracy: 0.9801 - val_loss: 0.0596\n",
            "Epoch 628/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9769 - loss: 0.0782 - val_accuracy: 0.9670 - val_loss: 0.1213\n",
            "Epoch 629/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9653 - loss: 0.1205 - val_accuracy: 0.9721 - val_loss: 0.0857\n",
            "Epoch 630/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9750 - loss: 0.0850 - val_accuracy: 0.9848 - val_loss: 0.0449\n",
            "Epoch 631/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9834 - loss: 0.0536 - val_accuracy: 0.9860 - val_loss: 0.0439\n",
            "Epoch 632/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9855 - loss: 0.0442 - val_accuracy: 0.9881 - val_loss: 0.0356\n",
            "Epoch 633/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9877 - loss: 0.0419 - val_accuracy: 0.9863 - val_loss: 0.0436\n",
            "Epoch 634/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0443 - val_accuracy: 0.9893 - val_loss: 0.0334\n",
            "Epoch 635/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.0317 - val_accuracy: 0.9925 - val_loss: 0.0235\n",
            "Epoch 636/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0342 - val_accuracy: 0.9858 - val_loss: 0.0417\n",
            "Epoch 637/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9870 - loss: 0.0393 - val_accuracy: 0.9855 - val_loss: 0.0428\n",
            "Epoch 638/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9857 - loss: 0.0481 - val_accuracy: 0.9730 - val_loss: 0.1017\n",
            "Epoch 639/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9653 - loss: 0.1285 - val_accuracy: 0.9484 - val_loss: 0.1880\n",
            "Epoch 640/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9517 - loss: 0.1886 - val_accuracy: 0.9344 - val_loss: 0.2471\n",
            "Epoch 641/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9445 - loss: 0.2070 - val_accuracy: 0.9692 - val_loss: 0.1056\n",
            "Epoch 642/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9645 - loss: 0.1209 - val_accuracy: 0.9779 - val_loss: 0.0712\n",
            "Epoch 643/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9744 - loss: 0.0843 - val_accuracy: 0.9827 - val_loss: 0.0538\n",
            "Epoch 644/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9783 - loss: 0.0694 - val_accuracy: 0.9651 - val_loss: 0.1124\n",
            "Epoch 645/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9750 - loss: 0.0808 - val_accuracy: 0.9817 - val_loss: 0.0610\n",
            "Epoch 646/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9819 - loss: 0.0609 - val_accuracy: 0.9902 - val_loss: 0.0300\n",
            "Epoch 647/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9891 - loss: 0.0342 - val_accuracy: 0.9907 - val_loss: 0.0268\n",
            "Epoch 648/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0388 - val_accuracy: 0.9872 - val_loss: 0.0424\n",
            "Epoch 649/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9871 - loss: 0.0396 - val_accuracy: 0.9799 - val_loss: 0.0622\n",
            "Epoch 650/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9731 - loss: 0.0872 - val_accuracy: 0.9699 - val_loss: 0.1075\n",
            "Epoch 651/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9757 - loss: 0.0809 - val_accuracy: 0.9731 - val_loss: 0.0954\n",
            "Epoch 652/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9603 - loss: 0.1413 - val_accuracy: 0.9537 - val_loss: 0.1653\n",
            "Epoch 653/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9431 - loss: 0.2064 - val_accuracy: 0.9645 - val_loss: 0.1191\n",
            "Epoch 654/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9741 - loss: 0.0874 - val_accuracy: 0.9820 - val_loss: 0.0557\n",
            "Epoch 655/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9822 - loss: 0.0593 - val_accuracy: 0.9894 - val_loss: 0.0365\n",
            "Epoch 656/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9895 - loss: 0.0337 - val_accuracy: 0.9961 - val_loss: 0.0138\n",
            "Epoch 657/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9951 - loss: 0.0159 - val_accuracy: 0.9974 - val_loss: 0.0094\n",
            "Epoch 658/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9968 - loss: 0.0104 - val_accuracy: 0.9989 - val_loss: 0.0056\n",
            "Epoch 659/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 0.9975 - val_loss: 0.0073\n",
            "Epoch 660/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 0.9989 - val_loss: 0.0056\n",
            "Epoch 661/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 0.9992 - val_loss: 0.0041\n",
            "Epoch 662/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0065 - val_accuracy: 0.9929 - val_loss: 0.0201\n",
            "Epoch 663/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9946 - loss: 0.0164 - val_accuracy: 0.9907 - val_loss: 0.0260\n",
            "Epoch 664/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9871 - loss: 0.0400 - val_accuracy: 0.9753 - val_loss: 0.0884\n",
            "Epoch 665/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9510 - loss: 0.1993 - val_accuracy: 0.9358 - val_loss: 0.2667\n",
            "Epoch 666/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9335 - loss: 0.2640 - val_accuracy: 0.9474 - val_loss: 0.1882\n",
            "Epoch 667/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9514 - loss: 0.1732 - val_accuracy: 0.9562 - val_loss: 0.1378\n",
            "Epoch 668/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9634 - loss: 0.1251 - val_accuracy: 0.9667 - val_loss: 0.1157\n",
            "Epoch 669/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9608 - loss: 0.1419 - val_accuracy: 0.9654 - val_loss: 0.1059\n",
            "Epoch 670/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9710 - loss: 0.0978 - val_accuracy: 0.9849 - val_loss: 0.0485\n",
            "Epoch 671/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9865 - loss: 0.0426 - val_accuracy: 0.9929 - val_loss: 0.0271\n",
            "Epoch 672/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0242 - val_accuracy: 0.9943 - val_loss: 0.0197\n",
            "Epoch 673/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9923 - loss: 0.0238 - val_accuracy: 0.9948 - val_loss: 0.0165\n",
            "Epoch 674/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9939 - loss: 0.0181 - val_accuracy: 0.9925 - val_loss: 0.0242\n",
            "Epoch 675/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0262 - val_accuracy: 0.9919 - val_loss: 0.0267\n",
            "Epoch 676/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0239 - val_accuracy: 0.9853 - val_loss: 0.0467\n",
            "Epoch 677/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9828 - loss: 0.0590 - val_accuracy: 0.9741 - val_loss: 0.0869\n",
            "Epoch 678/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9519 - loss: 0.1940 - val_accuracy: 0.9571 - val_loss: 0.1570\n",
            "Epoch 679/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9465 - loss: 0.1965 - val_accuracy: 0.9617 - val_loss: 0.1279\n",
            "Epoch 680/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9627 - loss: 0.1334 - val_accuracy: 0.9809 - val_loss: 0.0606\n",
            "Epoch 681/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9783 - loss: 0.0706 - val_accuracy: 0.9864 - val_loss: 0.0447\n",
            "Epoch 682/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9844 - loss: 0.0466 - val_accuracy: 0.9917 - val_loss: 0.0311\n",
            "Epoch 683/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0488 - val_accuracy: 0.9926 - val_loss: 0.0302\n",
            "Epoch 684/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0418 - val_accuracy: 0.9844 - val_loss: 0.0459\n",
            "Epoch 685/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9853 - loss: 0.0470 - val_accuracy: 0.9820 - val_loss: 0.0515\n",
            "Epoch 686/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9806 - loss: 0.0649 - val_accuracy: 0.9782 - val_loss: 0.0689\n",
            "Epoch 687/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9737 - loss: 0.0921 - val_accuracy: 0.9742 - val_loss: 0.0839\n",
            "Epoch 688/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9666 - loss: 0.1128 - val_accuracy: 0.9664 - val_loss: 0.1125\n",
            "Epoch 689/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9698 - loss: 0.1005 - val_accuracy: 0.9672 - val_loss: 0.1028\n",
            "Epoch 690/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9695 - loss: 0.1003 - val_accuracy: 0.9758 - val_loss: 0.0803\n",
            "Epoch 691/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9738 - loss: 0.0926 - val_accuracy: 0.9665 - val_loss: 0.1268\n",
            "Epoch 692/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9659 - loss: 0.1215 - val_accuracy: 0.9765 - val_loss: 0.0755\n",
            "Epoch 693/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9774 - loss: 0.0747 - val_accuracy: 0.9837 - val_loss: 0.0488\n",
            "Epoch 694/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0594 - val_accuracy: 0.9901 - val_loss: 0.0323\n",
            "Epoch 695/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0306 - val_accuracy: 0.9896 - val_loss: 0.0307\n",
            "Epoch 696/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9846 - loss: 0.0465 - val_accuracy: 0.9804 - val_loss: 0.0702\n",
            "Epoch 697/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9799 - loss: 0.0628 - val_accuracy: 0.9847 - val_loss: 0.0444\n",
            "Epoch 698/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0482 - val_accuracy: 0.9828 - val_loss: 0.0570\n",
            "Epoch 699/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9802 - loss: 0.0625 - val_accuracy: 0.9863 - val_loss: 0.0470\n",
            "Epoch 700/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9842 - loss: 0.0521 - val_accuracy: 0.9774 - val_loss: 0.0711\n",
            "Epoch 701/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9698 - loss: 0.1097 - val_accuracy: 0.9410 - val_loss: 0.2248\n",
            "Epoch 702/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9361 - loss: 0.2506 - val_accuracy: 0.9489 - val_loss: 0.2021\n",
            "Epoch 703/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9517 - loss: 0.1763 - val_accuracy: 0.9679 - val_loss: 0.1045\n",
            "Epoch 704/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9725 - loss: 0.0913 - val_accuracy: 0.9811 - val_loss: 0.0620\n",
            "Epoch 705/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9799 - loss: 0.0691 - val_accuracy: 0.9847 - val_loss: 0.0536\n",
            "Epoch 706/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9838 - loss: 0.0502 - val_accuracy: 0.9826 - val_loss: 0.0559\n",
            "Epoch 707/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9791 - loss: 0.0676 - val_accuracy: 0.9874 - val_loss: 0.0434\n",
            "Epoch 708/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9838 - loss: 0.0529 - val_accuracy: 0.9882 - val_loss: 0.0360\n",
            "Epoch 709/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9879 - loss: 0.0372 - val_accuracy: 0.9940 - val_loss: 0.0194\n",
            "Epoch 710/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9882 - loss: 0.0386 - val_accuracy: 0.9857 - val_loss: 0.0437\n",
            "Epoch 711/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9848 - loss: 0.0486 - val_accuracy: 0.9893 - val_loss: 0.0313\n",
            "Epoch 712/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0416 - val_accuracy: 0.9773 - val_loss: 0.0772\n",
            "Epoch 713/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9794 - loss: 0.0706 - val_accuracy: 0.9874 - val_loss: 0.0371\n",
            "Epoch 714/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9875 - loss: 0.0408 - val_accuracy: 0.9849 - val_loss: 0.0478\n",
            "Epoch 715/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0602 - val_accuracy: 0.9791 - val_loss: 0.0741\n",
            "Epoch 716/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9726 - loss: 0.1014 - val_accuracy: 0.9625 - val_loss: 0.1404\n",
            "Epoch 717/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9542 - loss: 0.1734 - val_accuracy: 0.9617 - val_loss: 0.1329\n",
            "Epoch 718/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9646 - loss: 0.1231 - val_accuracy: 0.9550 - val_loss: 0.1628\n",
            "Epoch 719/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9589 - loss: 0.1464 - val_accuracy: 0.9754 - val_loss: 0.0817\n",
            "Epoch 720/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9729 - loss: 0.0889 - val_accuracy: 0.9760 - val_loss: 0.0809\n",
            "Epoch 721/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9807 - loss: 0.0595 - val_accuracy: 0.9867 - val_loss: 0.0419\n",
            "Epoch 722/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0373 - val_accuracy: 0.9879 - val_loss: 0.0335\n",
            "Epoch 723/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0318 - val_accuracy: 0.9870 - val_loss: 0.0431\n",
            "Epoch 724/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.0485 - val_accuracy: 0.9901 - val_loss: 0.0302\n",
            "Epoch 725/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9887 - loss: 0.0348 - val_accuracy: 0.9949 - val_loss: 0.0179\n",
            "Epoch 726/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0278 - val_accuracy: 0.9885 - val_loss: 0.0354\n",
            "Epoch 727/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9855 - loss: 0.0455 - val_accuracy: 0.9743 - val_loss: 0.0881\n",
            "Epoch 728/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9703 - loss: 0.1117 - val_accuracy: 0.9427 - val_loss: 0.2207\n",
            "Epoch 729/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9507 - loss: 0.1952 - val_accuracy: 0.9545 - val_loss: 0.1697\n",
            "Epoch 730/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9564 - loss: 0.1488 - val_accuracy: 0.9790 - val_loss: 0.0659\n",
            "Epoch 731/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9832 - loss: 0.0531 - val_accuracy: 0.9881 - val_loss: 0.0369\n",
            "Epoch 732/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0323 - val_accuracy: 0.9955 - val_loss: 0.0150\n",
            "Epoch 733/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0234 - val_accuracy: 0.9878 - val_loss: 0.0371\n",
            "Epoch 734/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0476 - val_accuracy: 0.9873 - val_loss: 0.0456\n",
            "Epoch 735/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0472 - val_accuracy: 0.9858 - val_loss: 0.0427\n",
            "Epoch 736/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9831 - loss: 0.0539 - val_accuracy: 0.9838 - val_loss: 0.0510\n",
            "Epoch 737/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9790 - loss: 0.0710 - val_accuracy: 0.9728 - val_loss: 0.0950\n",
            "Epoch 738/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9712 - loss: 0.1022 - val_accuracy: 0.9758 - val_loss: 0.0817\n",
            "Epoch 739/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9690 - loss: 0.1046 - val_accuracy: 0.9769 - val_loss: 0.0740\n",
            "Epoch 740/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9735 - loss: 0.0883 - val_accuracy: 0.9828 - val_loss: 0.0579\n",
            "Epoch 741/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9759 - loss: 0.0854 - val_accuracy: 0.9746 - val_loss: 0.0824\n",
            "Epoch 742/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9718 - loss: 0.0995 - val_accuracy: 0.9762 - val_loss: 0.0779\n",
            "Epoch 743/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9721 - loss: 0.0969 - val_accuracy: 0.9664 - val_loss: 0.1119\n",
            "Epoch 744/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9705 - loss: 0.1041 - val_accuracy: 0.9789 - val_loss: 0.0733\n",
            "Epoch 745/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9727 - loss: 0.0950 - val_accuracy: 0.9826 - val_loss: 0.0542\n",
            "Epoch 746/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9820 - loss: 0.0597 - val_accuracy: 0.9809 - val_loss: 0.0626\n",
            "Epoch 747/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0662 - val_accuracy: 0.9774 - val_loss: 0.0798\n",
            "Epoch 748/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9823 - loss: 0.0575 - val_accuracy: 0.9856 - val_loss: 0.0450\n",
            "Epoch 749/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0379 - val_accuracy: 0.9746 - val_loss: 0.0967\n",
            "Epoch 750/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9802 - loss: 0.0699 - val_accuracy: 0.9780 - val_loss: 0.0742\n",
            "Epoch 751/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9705 - loss: 0.1067 - val_accuracy: 0.9816 - val_loss: 0.0672\n",
            "Epoch 752/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9760 - loss: 0.0832 - val_accuracy: 0.9808 - val_loss: 0.0633\n",
            "Epoch 753/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9747 - loss: 0.0869 - val_accuracy: 0.9608 - val_loss: 0.1512\n",
            "Epoch 754/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9701 - loss: 0.1080 - val_accuracy: 0.9779 - val_loss: 0.0748\n",
            "Epoch 755/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9790 - loss: 0.0688 - val_accuracy: 0.9814 - val_loss: 0.0658\n",
            "Epoch 756/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9824 - loss: 0.0578 - val_accuracy: 0.9879 - val_loss: 0.0426\n",
            "Epoch 757/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9847 - loss: 0.0487 - val_accuracy: 0.9903 - val_loss: 0.0287\n",
            "Epoch 758/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0331 - val_accuracy: 0.9852 - val_loss: 0.0518\n",
            "Epoch 759/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0319 - val_accuracy: 0.9879 - val_loss: 0.0442\n",
            "Epoch 760/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9875 - loss: 0.0397 - val_accuracy: 0.9828 - val_loss: 0.0527\n",
            "Epoch 761/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9816 - loss: 0.0659 - val_accuracy: 0.9757 - val_loss: 0.0986\n",
            "Epoch 762/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9690 - loss: 0.1143 - val_accuracy: 0.9543 - val_loss: 0.1875\n",
            "Epoch 763/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9465 - loss: 0.2124 - val_accuracy: 0.9561 - val_loss: 0.1634\n",
            "Epoch 764/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9620 - loss: 0.1443 - val_accuracy: 0.9715 - val_loss: 0.0984\n",
            "Epoch 765/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9686 - loss: 0.1114 - val_accuracy: 0.9793 - val_loss: 0.0656\n",
            "Epoch 766/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9784 - loss: 0.0694 - val_accuracy: 0.9746 - val_loss: 0.0882\n",
            "Epoch 767/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9747 - loss: 0.0903 - val_accuracy: 0.9892 - val_loss: 0.0334\n",
            "Epoch 768/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9862 - loss: 0.0414 - val_accuracy: 0.9847 - val_loss: 0.0494\n",
            "Epoch 769/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9853 - loss: 0.0463 - val_accuracy: 0.9838 - val_loss: 0.0494\n",
            "Epoch 770/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9855 - loss: 0.0474 - val_accuracy: 0.9905 - val_loss: 0.0295\n",
            "Epoch 771/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9915 - loss: 0.0277 - val_accuracy: 0.9962 - val_loss: 0.0136\n",
            "Epoch 772/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0237 - val_accuracy: 0.9941 - val_loss: 0.0190\n",
            "Epoch 773/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0336 - val_accuracy: 0.9933 - val_loss: 0.0245\n",
            "Epoch 774/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9890 - loss: 0.0360 - val_accuracy: 0.9847 - val_loss: 0.0484\n",
            "Epoch 775/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9842 - loss: 0.0495 - val_accuracy: 0.9879 - val_loss: 0.0342\n",
            "Epoch 776/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9846 - loss: 0.0507 - val_accuracy: 0.9828 - val_loss: 0.0616\n",
            "Epoch 777/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9772 - loss: 0.0851 - val_accuracy: 0.9705 - val_loss: 0.1157\n",
            "Epoch 778/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9640 - loss: 0.1342 - val_accuracy: 0.9570 - val_loss: 0.1702\n",
            "Epoch 779/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9599 - loss: 0.1500 - val_accuracy: 0.9703 - val_loss: 0.1100\n",
            "Epoch 780/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9646 - loss: 0.1364 - val_accuracy: 0.9669 - val_loss: 0.1253\n",
            "Epoch 781/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9650 - loss: 0.1276 - val_accuracy: 0.9865 - val_loss: 0.0422\n",
            "Epoch 782/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9799 - loss: 0.0683 - val_accuracy: 0.9787 - val_loss: 0.0667\n",
            "Epoch 783/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9746 - loss: 0.0866 - val_accuracy: 0.9825 - val_loss: 0.0596\n",
            "Epoch 784/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9825 - loss: 0.0595 - val_accuracy: 0.9886 - val_loss: 0.0378\n",
            "Epoch 785/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9875 - loss: 0.0405 - val_accuracy: 0.9927 - val_loss: 0.0207\n",
            "Epoch 786/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0242 - val_accuracy: 0.9951 - val_loss: 0.0154\n",
            "Epoch 787/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9946 - loss: 0.0166 - val_accuracy: 0.9918 - val_loss: 0.0239\n",
            "Epoch 788/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0276 - val_accuracy: 0.9832 - val_loss: 0.0576\n",
            "Epoch 789/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9856 - loss: 0.0515 - val_accuracy: 0.9726 - val_loss: 0.0976\n",
            "Epoch 790/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9668 - loss: 0.1236 - val_accuracy: 0.9741 - val_loss: 0.1010\n",
            "Epoch 791/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9621 - loss: 0.1429 - val_accuracy: 0.9554 - val_loss: 0.1804\n",
            "Epoch 792/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9613 - loss: 0.1474 - val_accuracy: 0.9742 - val_loss: 0.0936\n",
            "Epoch 793/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.1131 - val_accuracy: 0.9636 - val_loss: 0.1277\n",
            "Epoch 794/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9661 - loss: 0.1230 - val_accuracy: 0.9680 - val_loss: 0.1071\n",
            "Epoch 795/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9679 - loss: 0.1128 - val_accuracy: 0.9832 - val_loss: 0.0468\n",
            "Epoch 796/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0636 - val_accuracy: 0.9827 - val_loss: 0.0523\n",
            "Epoch 797/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9831 - loss: 0.0543 - val_accuracy: 0.9916 - val_loss: 0.0266\n",
            "Epoch 798/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9906 - loss: 0.0310 - val_accuracy: 0.9960 - val_loss: 0.0128\n",
            "Epoch 799/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9952 - loss: 0.0155 - val_accuracy: 0.9973 - val_loss: 0.0107\n",
            "Epoch 800/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9970 - loss: 0.0099 - val_accuracy: 0.9972 - val_loss: 0.0079\n",
            "Epoch 801/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9979 - loss: 0.0073 - val_accuracy: 0.9997 - val_loss: 0.0027\n",
            "Epoch 802/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 0.9994 - val_loss: 0.0032\n",
            "Epoch 803/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.9997 - val_loss: 0.0027\n",
            "Epoch 804/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.9996 - val_loss: 0.0020\n",
            "Epoch 805/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9999 - val_loss: 0.0013\n",
            "Epoch 806/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9998 - val_loss: 0.0013\n",
            "Epoch 807/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9998 - val_loss: 0.0013\n",
            "Epoch 808/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 0.0012\n",
            "Epoch 809/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 8.8552e-04\n",
            "Epoch 810/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9999 - val_loss: 0.0014\n",
            "Epoch 811/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9996 - val_loss: 0.0022\n",
            "Epoch 812/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9994 - val_loss: 0.0022\n",
            "Epoch 813/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9996 - val_loss: 0.0017\n",
            "Epoch 814/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9864 - val_loss: 0.0505\n",
            "Epoch 815/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9484 - loss: 0.2480 - val_accuracy: 0.8247 - val_loss: 0.8163\n",
            "Epoch 816/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8462 - loss: 0.6306 - val_accuracy: 0.9047 - val_loss: 0.3304\n",
            "Epoch 817/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9233 - loss: 0.2725 - val_accuracy: 0.9505 - val_loss: 0.1759\n",
            "Epoch 818/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9517 - loss: 0.1628 - val_accuracy: 0.9707 - val_loss: 0.0933\n",
            "Epoch 819/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9707 - loss: 0.0875 - val_accuracy: 0.9864 - val_loss: 0.0451\n",
            "Epoch 820/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9876 - loss: 0.0393 - val_accuracy: 0.9917 - val_loss: 0.0247\n",
            "Epoch 821/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0275 - val_accuracy: 0.9932 - val_loss: 0.0250\n",
            "Epoch 822/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0306 - val_accuracy: 0.9871 - val_loss: 0.0397\n",
            "Epoch 823/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9888 - loss: 0.0327 - val_accuracy: 0.9924 - val_loss: 0.0221\n",
            "Epoch 824/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9886 - loss: 0.0342 - val_accuracy: 0.9919 - val_loss: 0.0268\n",
            "Epoch 825/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9882 - loss: 0.0353 - val_accuracy: 0.9786 - val_loss: 0.0744\n",
            "Epoch 826/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9730 - loss: 0.0918 - val_accuracy: 0.9792 - val_loss: 0.0658\n",
            "Epoch 827/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9735 - loss: 0.0884 - val_accuracy: 0.9673 - val_loss: 0.1160\n",
            "Epoch 828/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9669 - loss: 0.1202 - val_accuracy: 0.9659 - val_loss: 0.1237\n",
            "Epoch 829/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9602 - loss: 0.1465 - val_accuracy: 0.9650 - val_loss: 0.1170\n",
            "Epoch 830/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9639 - loss: 0.1318 - val_accuracy: 0.9748 - val_loss: 0.0860\n",
            "Epoch 831/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9732 - loss: 0.0912 - val_accuracy: 0.9845 - val_loss: 0.0530\n",
            "Epoch 832/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9770 - loss: 0.0801 - val_accuracy: 0.9761 - val_loss: 0.0816\n",
            "Epoch 833/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9746 - loss: 0.0861 - val_accuracy: 0.9819 - val_loss: 0.0623\n",
            "Epoch 834/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9786 - loss: 0.0738 - val_accuracy: 0.9847 - val_loss: 0.0477\n",
            "Epoch 835/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0510 - val_accuracy: 0.9864 - val_loss: 0.0429\n",
            "Epoch 836/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9879 - loss: 0.0370 - val_accuracy: 0.9919 - val_loss: 0.0256\n",
            "Epoch 837/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9935 - loss: 0.0196 - val_accuracy: 0.9947 - val_loss: 0.0156\n",
            "Epoch 838/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9926 - loss: 0.0253 - val_accuracy: 0.9834 - val_loss: 0.0547\n",
            "Epoch 839/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9812 - loss: 0.0643 - val_accuracy: 0.9857 - val_loss: 0.0500\n",
            "Epoch 840/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9827 - loss: 0.0575 - val_accuracy: 0.9794 - val_loss: 0.0664\n",
            "Epoch 841/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9771 - loss: 0.0737 - val_accuracy: 0.9814 - val_loss: 0.0678\n",
            "Epoch 842/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9793 - loss: 0.0690 - val_accuracy: 0.9843 - val_loss: 0.0561\n",
            "Epoch 843/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9752 - loss: 0.0862 - val_accuracy: 0.9650 - val_loss: 0.1194\n",
            "Epoch 844/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9707 - loss: 0.1056 - val_accuracy: 0.9703 - val_loss: 0.1014\n",
            "Epoch 845/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9651 - loss: 0.1288 - val_accuracy: 0.9634 - val_loss: 0.1468\n",
            "Epoch 846/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9610 - loss: 0.1486 - val_accuracy: 0.9529 - val_loss: 0.1712\n",
            "Epoch 847/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9373 - loss: 0.2537 - val_accuracy: 0.9346 - val_loss: 0.2404\n",
            "Epoch 848/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9485 - loss: 0.1794 - val_accuracy: 0.9745 - val_loss: 0.0771\n",
            "Epoch 849/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9763 - loss: 0.0777 - val_accuracy: 0.9873 - val_loss: 0.0398\n",
            "Epoch 850/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0482 - val_accuracy: 0.9930 - val_loss: 0.0232\n",
            "Epoch 851/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0247 - val_accuracy: 0.9950 - val_loss: 0.0174\n",
            "Epoch 852/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9934 - loss: 0.0219 - val_accuracy: 0.9969 - val_loss: 0.0130\n",
            "Epoch 853/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9952 - loss: 0.0161 - val_accuracy: 0.9945 - val_loss: 0.0175\n",
            "Epoch 854/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0160 - val_accuracy: 0.9936 - val_loss: 0.0212\n",
            "Epoch 855/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0315 - val_accuracy: 0.9874 - val_loss: 0.0394\n",
            "Epoch 856/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0382 - val_accuracy: 0.9908 - val_loss: 0.0285\n",
            "Epoch 857/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9851 - loss: 0.0488 - val_accuracy: 0.9688 - val_loss: 0.1318\n",
            "Epoch 858/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9736 - loss: 0.0933 - val_accuracy: 0.9801 - val_loss: 0.0738\n",
            "Epoch 859/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9777 - loss: 0.0758 - val_accuracy: 0.9749 - val_loss: 0.0817\n",
            "Epoch 860/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9686 - loss: 0.1145 - val_accuracy: 0.9695 - val_loss: 0.1038\n",
            "Epoch 861/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9683 - loss: 0.1100 - val_accuracy: 0.9592 - val_loss: 0.1758\n",
            "Epoch 862/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9566 - loss: 0.1763 - val_accuracy: 0.9658 - val_loss: 0.1374\n",
            "Epoch 863/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9663 - loss: 0.1214 - val_accuracy: 0.9763 - val_loss: 0.0841\n",
            "Epoch 864/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9726 - loss: 0.0973 - val_accuracy: 0.9737 - val_loss: 0.0912\n",
            "Epoch 865/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9744 - loss: 0.0901 - val_accuracy: 0.9852 - val_loss: 0.0431\n",
            "Epoch 866/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9874 - loss: 0.0407 - val_accuracy: 0.9906 - val_loss: 0.0298\n",
            "Epoch 867/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9885 - loss: 0.0362 - val_accuracy: 0.9906 - val_loss: 0.0271\n",
            "Epoch 868/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0290 - val_accuracy: 0.9936 - val_loss: 0.0180\n",
            "Epoch 869/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9889 - loss: 0.0349 - val_accuracy: 0.9930 - val_loss: 0.0251\n",
            "Epoch 870/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0417 - val_accuracy: 0.9816 - val_loss: 0.0673\n",
            "Epoch 871/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9818 - loss: 0.0606 - val_accuracy: 0.9876 - val_loss: 0.0448\n",
            "Epoch 872/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0684 - val_accuracy: 0.9841 - val_loss: 0.0516\n",
            "Epoch 873/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9794 - loss: 0.0721 - val_accuracy: 0.9690 - val_loss: 0.1116\n",
            "Epoch 874/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9676 - loss: 0.1159 - val_accuracy: 0.9651 - val_loss: 0.1221\n",
            "Epoch 875/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9670 - loss: 0.1273 - val_accuracy: 0.9725 - val_loss: 0.1032\n",
            "Epoch 876/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9713 - loss: 0.0970 - val_accuracy: 0.9808 - val_loss: 0.0568\n",
            "Epoch 877/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9830 - loss: 0.0583 - val_accuracy: 0.9809 - val_loss: 0.0680\n",
            "Epoch 878/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0741 - val_accuracy: 0.9822 - val_loss: 0.0630\n",
            "Epoch 879/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9783 - loss: 0.0728 - val_accuracy: 0.9623 - val_loss: 0.1429\n",
            "Epoch 880/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9592 - loss: 0.1599 - val_accuracy: 0.9713 - val_loss: 0.0984\n",
            "Epoch 881/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9710 - loss: 0.1015 - val_accuracy: 0.9795 - val_loss: 0.0675\n",
            "Epoch 882/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9832 - loss: 0.0608 - val_accuracy: 0.9537 - val_loss: 0.2007\n",
            "Epoch 883/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9502 - loss: 0.1904 - val_accuracy: 0.9742 - val_loss: 0.0857\n",
            "Epoch 884/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9749 - loss: 0.0855 - val_accuracy: 0.9928 - val_loss: 0.0269\n",
            "Epoch 885/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9898 - loss: 0.0327 - val_accuracy: 0.9930 - val_loss: 0.0232\n",
            "Epoch 886/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0296 - val_accuracy: 0.9831 - val_loss: 0.0574\n",
            "Epoch 887/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9840 - loss: 0.0541 - val_accuracy: 0.9859 - val_loss: 0.0414\n",
            "Epoch 888/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9833 - loss: 0.0561 - val_accuracy: 0.9779 - val_loss: 0.0739\n",
            "Epoch 889/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9826 - loss: 0.0579 - val_accuracy: 0.9877 - val_loss: 0.0364\n",
            "Epoch 890/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0347 - val_accuracy: 0.9866 - val_loss: 0.0355\n",
            "Epoch 891/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9867 - loss: 0.0424 - val_accuracy: 0.9877 - val_loss: 0.0424\n",
            "Epoch 892/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9810 - loss: 0.0625 - val_accuracy: 0.9832 - val_loss: 0.0612\n",
            "Epoch 893/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9765 - loss: 0.0834 - val_accuracy: 0.9654 - val_loss: 0.1199\n",
            "Epoch 894/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9684 - loss: 0.1140 - val_accuracy: 0.9811 - val_loss: 0.0721\n",
            "Epoch 895/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9759 - loss: 0.0854 - val_accuracy: 0.9713 - val_loss: 0.1001\n",
            "Epoch 896/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9719 - loss: 0.0979 - val_accuracy: 0.9805 - val_loss: 0.0719\n",
            "Epoch 897/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9774 - loss: 0.0769 - val_accuracy: 0.9804 - val_loss: 0.0612\n",
            "Epoch 898/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9791 - loss: 0.0718 - val_accuracy: 0.9816 - val_loss: 0.0652\n",
            "Epoch 899/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9783 - loss: 0.0802 - val_accuracy: 0.9794 - val_loss: 0.0756\n",
            "Epoch 900/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9733 - loss: 0.0965 - val_accuracy: 0.9786 - val_loss: 0.0727\n",
            "Epoch 901/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9797 - loss: 0.0748 - val_accuracy: 0.9827 - val_loss: 0.0542\n",
            "Epoch 902/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9864 - loss: 0.0420 - val_accuracy: 0.9899 - val_loss: 0.0361\n",
            "Epoch 903/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9874 - loss: 0.0395 - val_accuracy: 0.9909 - val_loss: 0.0307\n",
            "Epoch 904/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0297 - val_accuracy: 0.9920 - val_loss: 0.0280\n",
            "Epoch 905/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9885 - loss: 0.0358 - val_accuracy: 0.9884 - val_loss: 0.0354\n",
            "Epoch 906/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9835 - loss: 0.0591 - val_accuracy: 0.9852 - val_loss: 0.0454\n",
            "Epoch 907/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9814 - loss: 0.0673 - val_accuracy: 0.9781 - val_loss: 0.0835\n",
            "Epoch 908/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9751 - loss: 0.0928 - val_accuracy: 0.9686 - val_loss: 0.1036\n",
            "Epoch 909/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9656 - loss: 0.1270 - val_accuracy: 0.9566 - val_loss: 0.1725\n",
            "Epoch 910/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9620 - loss: 0.1454 - val_accuracy: 0.9694 - val_loss: 0.1158\n",
            "Epoch 911/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9672 - loss: 0.1189 - val_accuracy: 0.9766 - val_loss: 0.0728\n",
            "Epoch 912/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9776 - loss: 0.0768 - val_accuracy: 0.9860 - val_loss: 0.0429\n",
            "Epoch 913/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9887 - loss: 0.0397 - val_accuracy: 0.9853 - val_loss: 0.0459\n",
            "Epoch 914/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0497 - val_accuracy: 0.9884 - val_loss: 0.0399\n",
            "Epoch 915/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9875 - loss: 0.0436 - val_accuracy: 0.9872 - val_loss: 0.0447\n",
            "Epoch 916/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9829 - loss: 0.0547 - val_accuracy: 0.9846 - val_loss: 0.0483\n",
            "Epoch 917/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9813 - loss: 0.0641 - val_accuracy: 0.9822 - val_loss: 0.0590\n",
            "Epoch 918/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9786 - loss: 0.0736 - val_accuracy: 0.9883 - val_loss: 0.0375\n",
            "Epoch 919/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9814 - loss: 0.0630 - val_accuracy: 0.9867 - val_loss: 0.0431\n",
            "Epoch 920/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0423 - val_accuracy: 0.9874 - val_loss: 0.0385\n",
            "Epoch 921/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9873 - loss: 0.0405 - val_accuracy: 0.9891 - val_loss: 0.0373\n",
            "Epoch 922/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9870 - loss: 0.0438 - val_accuracy: 0.9915 - val_loss: 0.0277\n",
            "Epoch 923/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0309 - val_accuracy: 0.9894 - val_loss: 0.0374\n",
            "Epoch 924/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9843 - loss: 0.0556 - val_accuracy: 0.9658 - val_loss: 0.1354\n",
            "Epoch 925/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9631 - loss: 0.1556 - val_accuracy: 0.9498 - val_loss: 0.1870\n",
            "Epoch 926/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9509 - loss: 0.1943 - val_accuracy: 0.9580 - val_loss: 0.1644\n",
            "Epoch 927/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9572 - loss: 0.1588 - val_accuracy: 0.9733 - val_loss: 0.0879\n",
            "Epoch 928/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9738 - loss: 0.0924 - val_accuracy: 0.9804 - val_loss: 0.0687\n",
            "Epoch 929/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9801 - loss: 0.0676 - val_accuracy: 0.9879 - val_loss: 0.0393\n",
            "Epoch 930/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0517 - val_accuracy: 0.9795 - val_loss: 0.0707\n",
            "Epoch 931/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9865 - loss: 0.0399 - val_accuracy: 0.9933 - val_loss: 0.0205\n",
            "Epoch 932/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.0255 - val_accuracy: 0.9921 - val_loss: 0.0243\n",
            "Epoch 933/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9887 - loss: 0.0355 - val_accuracy: 0.9918 - val_loss: 0.0262\n",
            "Epoch 934/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0258 - val_accuracy: 0.9886 - val_loss: 0.0378\n",
            "Epoch 935/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0283 - val_accuracy: 0.9937 - val_loss: 0.0228\n",
            "Epoch 936/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9885 - loss: 0.0414 - val_accuracy: 0.9735 - val_loss: 0.1020\n",
            "Epoch 937/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9733 - loss: 0.1000 - val_accuracy: 0.9758 - val_loss: 0.0965\n",
            "Epoch 938/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9672 - loss: 0.1265 - val_accuracy: 0.9500 - val_loss: 0.2012\n",
            "Epoch 939/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9538 - loss: 0.1755 - val_accuracy: 0.9614 - val_loss: 0.1530\n",
            "Epoch 940/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9679 - loss: 0.1128 - val_accuracy: 0.9833 - val_loss: 0.0549\n",
            "Epoch 941/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9757 - loss: 0.0956 - val_accuracy: 0.9779 - val_loss: 0.0830\n",
            "Epoch 942/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9809 - loss: 0.0653 - val_accuracy: 0.9836 - val_loss: 0.0539\n",
            "Epoch 943/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9857 - loss: 0.0520 - val_accuracy: 0.9915 - val_loss: 0.0247\n",
            "Epoch 944/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9892 - loss: 0.0335 - val_accuracy: 0.9878 - val_loss: 0.0378\n",
            "Epoch 945/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0277 - val_accuracy: 0.9964 - val_loss: 0.0107\n",
            "Epoch 946/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0238 - val_accuracy: 0.9938 - val_loss: 0.0171\n",
            "Epoch 947/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0165 - val_accuracy: 0.9884 - val_loss: 0.0400\n",
            "Epoch 948/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9906 - loss: 0.0307 - val_accuracy: 0.9958 - val_loss: 0.0176\n",
            "Epoch 949/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9898 - loss: 0.0349 - val_accuracy: 0.9741 - val_loss: 0.0883\n",
            "Epoch 950/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9714 - loss: 0.1094 - val_accuracy: 0.9596 - val_loss: 0.1426\n",
            "Epoch 951/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9599 - loss: 0.1645 - val_accuracy: 0.9492 - val_loss: 0.2155\n",
            "Epoch 952/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9479 - loss: 0.2104 - val_accuracy: 0.9520 - val_loss: 0.1839\n",
            "Epoch 953/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9637 - loss: 0.1343 - val_accuracy: 0.9768 - val_loss: 0.0767\n",
            "Epoch 954/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9774 - loss: 0.0830 - val_accuracy: 0.9815 - val_loss: 0.0691\n",
            "Epoch 955/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9801 - loss: 0.0665 - val_accuracy: 0.9870 - val_loss: 0.0445\n",
            "Epoch 956/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0412 - val_accuracy: 0.9891 - val_loss: 0.0391\n",
            "Epoch 957/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0513 - val_accuracy: 0.9863 - val_loss: 0.0438\n",
            "Epoch 958/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9885 - loss: 0.0358 - val_accuracy: 0.9855 - val_loss: 0.0514\n",
            "Epoch 959/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9862 - loss: 0.0493 - val_accuracy: 0.9882 - val_loss: 0.0459\n",
            "Epoch 960/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0446 - val_accuracy: 0.9830 - val_loss: 0.0666\n",
            "Epoch 961/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0662 - val_accuracy: 0.9875 - val_loss: 0.0406\n",
            "Epoch 962/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0581 - val_accuracy: 0.9817 - val_loss: 0.0573\n",
            "Epoch 963/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9815 - loss: 0.0698 - val_accuracy: 0.9874 - val_loss: 0.0453\n",
            "Epoch 964/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9775 - loss: 0.0862 - val_accuracy: 0.9737 - val_loss: 0.1001\n",
            "Epoch 965/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9701 - loss: 0.1169 - val_accuracy: 0.9512 - val_loss: 0.1855\n",
            "Epoch 966/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9610 - loss: 0.1532 - val_accuracy: 0.9701 - val_loss: 0.1256\n",
            "Epoch 967/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9726 - loss: 0.1017 - val_accuracy: 0.9746 - val_loss: 0.0802\n",
            "Epoch 968/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9723 - loss: 0.0982 - val_accuracy: 0.9809 - val_loss: 0.0644\n",
            "Epoch 969/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9805 - loss: 0.0681 - val_accuracy: 0.9771 - val_loss: 0.0867\n",
            "Epoch 970/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9809 - loss: 0.0698 - val_accuracy: 0.9746 - val_loss: 0.0915\n",
            "Epoch 971/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9685 - loss: 0.1238 - val_accuracy: 0.9678 - val_loss: 0.1235\n",
            "Epoch 972/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9690 - loss: 0.1178 - val_accuracy: 0.9770 - val_loss: 0.0817\n",
            "Epoch 973/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9773 - loss: 0.0809 - val_accuracy: 0.9907 - val_loss: 0.0334\n",
            "Epoch 974/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9895 - loss: 0.0334 - val_accuracy: 0.9889 - val_loss: 0.0348\n",
            "Epoch 975/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9877 - loss: 0.0452 - val_accuracy: 0.9927 - val_loss: 0.0244\n",
            "Epoch 976/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0234 - val_accuracy: 0.9928 - val_loss: 0.0238\n",
            "Epoch 977/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0499 - val_accuracy: 0.9824 - val_loss: 0.0631\n",
            "Epoch 978/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9815 - loss: 0.0700 - val_accuracy: 0.9790 - val_loss: 0.0785\n",
            "Epoch 979/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9762 - loss: 0.0897 - val_accuracy: 0.9829 - val_loss: 0.0632\n",
            "Epoch 980/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9823 - loss: 0.0569 - val_accuracy: 0.9839 - val_loss: 0.0580\n",
            "Epoch 981/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9804 - loss: 0.0690 - val_accuracy: 0.9836 - val_loss: 0.0576\n",
            "Epoch 982/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9759 - loss: 0.0925 - val_accuracy: 0.9750 - val_loss: 0.0987\n",
            "Epoch 983/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9703 - loss: 0.1204 - val_accuracy: 0.9754 - val_loss: 0.0871\n",
            "Epoch 984/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9763 - loss: 0.0828 - val_accuracy: 0.9821 - val_loss: 0.0558\n",
            "Epoch 985/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9760 - loss: 0.0880 - val_accuracy: 0.9870 - val_loss: 0.0501\n",
            "Epoch 986/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9810 - loss: 0.0637 - val_accuracy: 0.9912 - val_loss: 0.0313\n",
            "Epoch 987/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9855 - loss: 0.0510 - val_accuracy: 0.9823 - val_loss: 0.0654\n",
            "Epoch 988/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9770 - loss: 0.0836 - val_accuracy: 0.9794 - val_loss: 0.0750\n",
            "Epoch 989/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9790 - loss: 0.0728 - val_accuracy: 0.9848 - val_loss: 0.0584\n",
            "Epoch 990/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0670 - val_accuracy: 0.9829 - val_loss: 0.0577\n",
            "Epoch 991/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0573 - val_accuracy: 0.9839 - val_loss: 0.0602\n",
            "Epoch 992/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9738 - loss: 0.0989 - val_accuracy: 0.9627 - val_loss: 0.1476\n",
            "Epoch 993/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9660 - loss: 0.1366 - val_accuracy: 0.9584 - val_loss: 0.1574\n",
            "Epoch 994/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9669 - loss: 0.1258 - val_accuracy: 0.9786 - val_loss: 0.0793\n",
            "Epoch 995/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9763 - loss: 0.0885 - val_accuracy: 0.9815 - val_loss: 0.0603\n",
            "Epoch 996/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9817 - loss: 0.0621 - val_accuracy: 0.9884 - val_loss: 0.0365\n",
            "Epoch 997/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9901 - loss: 0.0310 - val_accuracy: 0.9932 - val_loss: 0.0210\n",
            "Epoch 998/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0231 - val_accuracy: 0.9946 - val_loss: 0.0154\n",
            "Epoch 999/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9944 - loss: 0.0178 - val_accuracy: 0.9930 - val_loss: 0.0229\n",
            "Epoch 1000/1000\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9951 - loss: 0.0166 - val_accuracy: 0.9942 - val_loss: 0.0220\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a90ffd469b0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "batch_size = 1024\n",
        "#def main():\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "images = np.concatenate([train_images, test_images], axis=0)\n",
        "labels = np.concatenate([train_labels, test_labels], axis=0)\n",
        "\n",
        "train_generator = SimpleCIFAR10DataGenerator(\n",
        "    images=images,\n",
        "    labels=labels,\n",
        "    batch_size=batch_size,\n",
        "    num_classes=10,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = SimpleCIFAR10DataGenerator(\n",
        "    images=test_images,\n",
        "    labels=test_labels,\n",
        "    batch_size=batch_size,\n",
        "    num_classes=10,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "if model is None:\n",
        "  print(\"creating large model\")\n",
        "  model = create_large_model(num_classes=10)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=1000,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "#main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets save our model\n",
        "model.save(\"color_model.keras\")"
      ],
      "metadata": {
        "id": "vAeoyrAwLgc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68ump2al62gG"
      },
      "source": [
        "## When to use a Sequential model\n",
        "\n",
        "A `Sequential` model is appropriate for **a plain stack of layers**\n",
        "where each layer has **exactly one input tensor and one output tensor**.\n",
        "\n",
        "Schematically, the following `Sequential` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWqBjZng62gG"
      },
      "outputs": [],
      "source": [
        "# Define Sequential model with 3 layers\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
        "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
        "        layers.Dense(4, name=\"layer3\"),\n",
        "    ]\n",
        ")\n",
        "# Call model on a test input\n",
        "x = ops.ones((3, 3))\n",
        "y = model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSbBLXRj62gG"
      },
      "source": [
        "is equivalent to this function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIvIuq5G62gG"
      },
      "outputs": [],
      "source": [
        "# Create 3 layers\n",
        "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
        "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
        "layer3 = layers.Dense(4, name=\"layer3\")\n",
        "\n",
        "# Call layers on a test input\n",
        "x = ops.ones((3, 3))\n",
        "y = layer3(layer2(layer1(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOx5Pf0I62gH"
      },
      "source": [
        "A Sequential model is **not appropriate** when:\n",
        "\n",
        "- Your model has multiple inputs or multiple outputs\n",
        "- Any of your layers has multiple inputs or multiple outputs\n",
        "- You need to do layer sharing\n",
        "- You want non-linear topology (e.g. a residual connection, a multi-branch\n",
        "model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZME71sf462gH"
      },
      "source": [
        "## Creating a Sequential model\n",
        "\n",
        "You can create a Sequential model by passing a list of layers to the Sequential\n",
        "constructor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWHEQu2d62gH"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(2, activation=\"relu\"),\n",
        "        layers.Dense(3, activation=\"relu\"),\n",
        "        layers.Dense(4),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLsuhmOA62gH"
      },
      "source": [
        "Its layers are accessible via the `layers` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytOAFQ3Z62gH",
        "outputId": "faefcd52-976d-43b9-92cb-e6103f4242da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Dense name=dense, built=False>,\n",
              " <Dense name=dense_1, built=False>,\n",
              " <Dense name=dense_2, built=False>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QabvuW0q62gH"
      },
      "source": [
        "You can also create a Sequential model incrementally via the `add()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gQC5dkj62gH"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(2, activation=\"relu\"))\n",
        "model.add(layers.Dense(3, activation=\"relu\"))\n",
        "model.add(layers.Dense(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdZQ8PvD62gI"
      },
      "source": [
        "Note that there's also a corresponding `pop()` method to remove layers:\n",
        "a Sequential model behaves very much like a list of layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O9r3qbW62gI",
        "outputId": "a8595d1f-9178-4c22-fa89-9aab4488044e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "model.pop()\n",
        "print(len(model.layers))  # 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eM_2njA62gI"
      },
      "source": [
        "Also note that the Sequential constructor accepts a `name` argument, just like\n",
        "any layer or model in Keras. This is useful to annotate TensorBoard graphs\n",
        "with semantically meaningful names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKRAK0xE62gI"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(name=\"my_sequential\")\n",
        "model.add(layers.Dense(2, activation=\"relu\", name=\"layer1\"))\n",
        "model.add(layers.Dense(3, activation=\"relu\", name=\"layer2\"))\n",
        "model.add(layers.Dense(4, name=\"layer3\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RilZ3n-B62gI"
      },
      "source": [
        "## Specifying the input shape in advance\n",
        "\n",
        "Generally, all layers in Keras need to know the shape of their inputs\n",
        "in order to be able to create their weights. So when you create a layer like\n",
        "this, initially, it has no weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ArTbhPx62gI",
        "outputId": "6443a32a-e4ad-4fa7-b8c9-2a56d1ba8b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "layer = layers.Dense(3)\n",
        "layer.weights  # Empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRRlxEEB62gI"
      },
      "source": [
        "It creates its weights the first time it is called on an input, since the shape\n",
        "of the weights depends on the shape of the inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWov3XSC62gI",
        "outputId": "4a4c524e-6aa8-4c4a-f8c8-d96df734a0ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(4, 3), dtype=float32, path=dense_6/kernel>,\n",
              " <KerasVariable shape=(3,), dtype=float32, path=dense_6/bias>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Call layer on a test input\n",
        "x = ops.ones((1, 4))\n",
        "y = layer(x)\n",
        "layer.weights  # Now it has weights, of shape (4, 3) and (3,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqnZSZjH62gI"
      },
      "source": [
        "Naturally, this also applies to Sequential models. When you instantiate a\n",
        "Sequential model without an input shape, it isn't \"built\": it has no weights\n",
        "(and calling\n",
        "`model.weights` results in an error stating just this). The weights are created\n",
        "when the model first sees some input data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPNF7etm62gI",
        "outputId": "c7fa2e46-3ea6-42e7-a96e-34fecee50850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of weights after calling the model: 6\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(2, activation=\"relu\"),\n",
        "        layers.Dense(3, activation=\"relu\"),\n",
        "        layers.Dense(4),\n",
        "    ]\n",
        ")  # No weights at this stage!\n",
        "\n",
        "# At this point, you can't do this:\n",
        "# model.weights\n",
        "\n",
        "# You also can't do this:\n",
        "# model.summary()\n",
        "\n",
        "# Call the model on a test input\n",
        "x = ops.ones((1, 4))\n",
        "y = model(x)\n",
        "print(\"Number of weights after calling the model:\", len(model.weights))  # 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2u3flc_62gJ"
      },
      "source": [
        "Once a model is \"built\", you can call its `summary()` method to display its\n",
        "contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs8jB3_d62gJ",
        "outputId": "aa10d76f-c116-483f-b00d-1ffd959263a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)                      │              \u001b[38;5;34m10\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)                      │               \u001b[38;5;34m9\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)                      │              \u001b[38;5;34m16\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35\u001b[0m (140.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35</span> (140.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35\u001b[0m (140.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35</span> (140.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpPTM8FW62gJ"
      },
      "source": [
        "However, it can be very useful when building a Sequential model incrementally\n",
        "to be able to display the summary of the model so far, including the current\n",
        "output shape. In this case, you should start your model by passing an `Input`\n",
        "object to your model, so that it knows its input shape from the start:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y48Mkqn62gJ",
        "outputId": "098b852c-a9f6-47e3-a74b-96ee56d76281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m10\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(4,)))\n",
        "model.add(layers.Dense(2, activation=\"relu\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGMUJvJx62gJ"
      },
      "source": [
        "Note that the `Input` object is not displayed as part of `model.layers`, since\n",
        "it isn't a layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PQCslLp62gJ",
        "outputId": "d423f418-f19e-4408-c9a5-0b2f2068d482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Dense name=dense_11, built=True>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xce6QEoW62gJ"
      },
      "source": [
        "Models built with a predefined input shape like this always have weights (even\n",
        "before seeing any data) and always have a defined output shape.\n",
        "\n",
        "In general, it's a recommended best practice to always specify the input shape\n",
        "of a Sequential model in advance if you know what it is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHP72JeN62gJ"
      },
      "source": [
        "## A common debugging workflow: `add()` + `summary()`\n",
        "\n",
        "When building a new Sequential architecture, it's useful to incrementally stack\n",
        "layers with `add()` and frequently print model summaries. For instance, this\n",
        "enables you to monitor how a stack of `Conv2D` and `MaxPooling2D` layers is\n",
        "downsampling image feature maps:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = None\n",
        "train_captions = None\n",
        "test_images = None\n",
        "test_captions = None\n",
        "train_image_rg = None\n",
        "train_image_rb = None\n",
        "train_image_gb = None\n",
        "train_image_ra = None\n",
        "train_image_ga = None\n",
        "train_image_ba = None\n",
        "train_image_rba = None\n",
        "train_image_rga = None\n",
        "train_image_bga = None\n",
        "classes = [\n",
        "  \"airplane\", #0\n",
        "  \"automobile\", #1\n",
        "  \"bird\", #2\n",
        "  \"cat\", #3\n",
        "  \"deer\", #4\n",
        "  \"dog\", #5\n",
        "  \"frog\", #6\n",
        "  \"horse\", #7\n",
        "  \"ship\", #8\n",
        "  \"truck\", #9\n",
        "  ]"
      ],
      "metadata": {
        "id": "b0YQxMBHf95C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def prepare_dataset(image_width, image_height, num_classes=10):\n",
        "    # Load CIFAR-10 dataset\n",
        "    (train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    train_images = train_images.astype('float32') / 255.0\n",
        "    test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "    # Resize images to (image_width, image_height)\n",
        "    train_resized = tf.image.resize(train_images, [image_width, image_height]).numpy()\n",
        "    test_resized = tf.image.resize(test_images, [image_width, image_height]).numpy()\n",
        "\n",
        "    # Add Alpha channel (set to 1.0 for full opacity)\n",
        "    def add_alpha_channel(images):\n",
        "        alpha_channel = np.ones((images.shape[0], image_width, image_height, 1), dtype=np.float32)\n",
        "        return np.concatenate([images, alpha_channel], axis=-1)\n",
        "\n",
        "    train_rgba = add_alpha_channel(train_resized)\n",
        "    test_rgba = add_alpha_channel(test_resized)\n",
        "\n",
        "    # Create color combination inputs\n",
        "    # Pair Inputs: (2 channels)\n",
        "    train_rg = train_rgba[..., [0, 1]]  # Red + Green\n",
        "    test_rg = test_rgba[..., [0, 1]]\n",
        "\n",
        "    train_rb = train_rgba[..., [0, 2]]  # Red + Blue\n",
        "    test_rb = test_rgba[..., [0, 2]]\n",
        "\n",
        "    train_gb = train_rgba[..., [1, 2]]  # Green + Blue\n",
        "    test_gb = test_rgba[..., [1, 2]]\n",
        "\n",
        "    train_ra = train_rgba[..., [0, 3]]  # Red + Alpha\n",
        "    test_ra = test_rgba[..., [0, 3]]\n",
        "\n",
        "    train_ga = train_rgba[..., [1, 3]]  # Green + Alpha\n",
        "    test_ga = test_rgba[..., [1, 3]]\n",
        "\n",
        "    train_ba = train_rgba[..., [2, 3]]  # Blue + Alpha\n",
        "    test_ba = test_rgba[..., [2, 3]]\n",
        "\n",
        "    # Triplet Inputs: (3 channels)\n",
        "    train_rba = train_rgba[..., [0, 2, 3]]  # Red + Blue + Alpha\n",
        "    test_rba = test_rgba[..., [0, 2, 3]]\n",
        "\n",
        "    train_rga = train_rgba[..., [0, 1, 3]]  # Red + Green + Alpha\n",
        "    test_rga = test_rgba[..., [0, 1, 3]]\n",
        "\n",
        "    train_bga = train_rgba[..., [2, 1, 3]]  # Blue + Green + Alpha\n",
        "    test_bga = test_rgba[..., [2, 1, 3]]\n",
        "\n",
        "    # One-hot encode labels\n",
        "    train_labels = to_categorical(train_labels, num_classes)\n",
        "    test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "    # Organize inputs into dictionaries\n",
        "    train_inputs = {\n",
        "        \"rgba_input\": train_rgba,\n",
        "        \"rg_input\": train_rg,\n",
        "        \"rb_input\": train_rb,\n",
        "        \"gb_input\": train_gb,\n",
        "        \"ra_input\": train_ra,\n",
        "        \"ga_input\": train_ga,\n",
        "        \"ba_input\": train_ba,\n",
        "        \"rba_input\": train_rba,\n",
        "        \"rga_input\": train_rga,\n",
        "        \"bga_input\": train_bga\n",
        "    }\n",
        "\n",
        "    test_inputs = {\n",
        "        \"rgba_input\": test_rgba,\n",
        "        \"rg_input\": test_rg,\n",
        "        \"rb_input\": test_rb,\n",
        "        \"gb_input\": test_gb,\n",
        "        \"ra_input\": test_ra,\n",
        "        \"ga_input\": test_ga,\n",
        "        \"ba_input\": test_ba,\n",
        "        \"rba_input\": test_rba,\n",
        "        \"rga_input\": test_rga,\n",
        "        \"bga_input\": test_bga\n",
        "    }\n",
        "\n",
        "    return train_inputs, train_labels, test_inputs, test_labels\n"
      ],
      "metadata": {
        "id": "FL-tusTQkaHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_data_shapes(train_inputs, test_inputs):\n",
        "    print(\"Training Inputs Shapes:\")\n",
        "    for key, value in train_inputs.items():\n",
        "        print(f\"{key}: {value.shape}\")\n",
        "\n",
        "    print(\"\\nTesting Inputs Shapes:\")\n",
        "    for key, value in test_inputs.items():\n",
        "        print(f\"{key}: {value.shape}\")"
      ],
      "metadata": {
        "id": "tL5mHur9uwr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VkCeKlGXusC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_parent_model(image_width, image_height, num_classes=10):\n",
        "    rgba_input = keras.Input(shape=(image_width, image_height, 4), name=\"rgba_input\")\n",
        "\n",
        "    rg_input = keras.Input(shape=(image_width, image_height, 2), name=\"rg_input\")\n",
        "    rb_input = keras.Input(shape=(image_width, image_height, 2), name=\"rb_input\")\n",
        "    gb_input = keras.Input(shape=(image_width, image_height, 2), name=\"gb_input\")\n",
        "\n",
        "    ra_input = keras.Input(shape=(image_width, image_height, 2), name=\"ra_input\")\n",
        "    ga_input = keras.Input(shape=(image_width, image_height, 2), name=\"ga_input\")\n",
        "    ba_input = keras.Input(shape=(image_width, image_height, 2), name=\"ba_input\")\n",
        "\n",
        "    rga_input = keras.Input(shape=(image_width, image_height, 3), name=\"rga_input\")\n",
        "    bga_input = keras.Input(shape=(image_width, image_height, 3), name=\"bga_input\")\n",
        "    rba_input = keras.Input(shape=(image_width, image_height, 3), name=\"rba_input\")\n",
        "    # Flatten all inputs before passing to Dense layers\n",
        "    rgba_flat = layers.Flatten()(rgba_input)\n",
        "    rg_flat = layers.Flatten()(rg_input)\n",
        "    rb_flat = layers.Flatten()(rb_input)\n",
        "    gb_flat = layers.Flatten()(gb_input)\n",
        "    ra_flat = layers.Flatten()(ra_input)\n",
        "    ga_flat = layers.Flatten()(ga_input)\n",
        "    ba_flat = layers.Flatten()(ba_input)\n",
        "    rga_flat = layers.Flatten()(rga_input)\n",
        "    bga_flat = layers.Flatten()(bga_input)\n",
        "    rba_flat = layers.Flatten()(rba_input)\n",
        "\n",
        "    # rgba\n",
        "\n",
        "    rgba = layers.Dense(1024, activation=\"relu\", name=\"rgba_dense_1\")(rgba_flat)\n",
        "    rgba = layers.Dense(1024, activation=\"relu\", name=\"rgba_dense_2\")(rgba)\n",
        "\n",
        "    # red + green\n",
        "    rg = layers.Dense(1024, activation=\"relu\", name=\"rg_dense_1\")(rg_flat)\n",
        "    rg = layers.Dense(1024, activation=\"relu\", name=\"rg_dense_2\")(rg)\n",
        "    # green + blue\n",
        "    gb = layers.Dense(1024, activation=\"relu\", name=\"gb_dense_1\")(gb_flat)\n",
        "    gb = layers.Dense(1024, activation=\"relu\", name=\"gb_dense_2\")(gb)\n",
        "    # red + blue\n",
        "    rb = layers.Dense(1024, activation=\"relu\", name=\"rb_dense_1\")(rb_flat)\n",
        "    rb = layers.Dense(1024, activation=\"relu\", name=\"rb_dense_2\")(rb)\n",
        "    # red + alpha\n",
        "    ra = layers.Dense(1024, activation=\"relu\", name=\"ra_dense_1\")(ra_flat)\n",
        "    ra = layers.Dense(1024, activation=\"relu\", name=\"ra_dense_2\")(ra)\n",
        "    # green + alpha\n",
        "    ga = layers.Dense(1024, activation=\"relu\", name=\"ga_dense_1\")(ga_flat)\n",
        "    ga = layers.Dense(1024, activation=\"relu\", name=\"ga_dense_2\")(ga)\n",
        "    # blue + alpha\n",
        "    ba = layers.Dense(1024, activation=\"relu\", name=\"ba_dense_1\")(ba_flat)\n",
        "    ba = layers.Dense(1024, activation=\"relu\", name=\"ba_dense_2\")(ba)\n",
        "    # red + green + alpha\n",
        "    rga = layers.Dense(1024, activation=\"relu\", name=\"rga_dense_1\")(rga_flat)\n",
        "    rga = layers.Dense(1024, activation=\"relu\", name=\"rga_dense_2\")(rga)\n",
        "    # blue + green + alpha\n",
        "    bga = layers.Dense(1024, activation=\"relu\", name=\"bga_dense_1\")(bga_flat)\n",
        "    bga = layers.Dense(1024, activation=\"relu\", name=\"bga_dense_2\")(bga)\n",
        "    # red + blue + alpha\n",
        "    rba = layers.Dense(1024, activation=\"relu\", name=\"rba_dense_1\")(rba_flat)\n",
        "    rba = layers.Dense(1024, activation=\"relu\", name=\"rba_dense_2\")(rba)\n",
        "\n",
        "    # Concatenate all processed inputs\n",
        "    color_layers = layers.concatenate([rgba, rg, gb, rb, ra, ga, ba, rga, bga, rba], name=\"color_concatenation\")\n",
        "    #color_layers = layers.concatenate([rgba, rg, gb, rb, ra, ga, ba], name=\"color_concatenation\")\n",
        "    color_layers = layers.Flatten()(color_layers)\n",
        "\n",
        "    # Further Dense layers\n",
        "    dense_color_1 = layers.Dense(1024, activation=\"relu\", name=\"dense_color_1\")(color_layers)\n",
        "    dense_color_2 = layers.Dense(512, activation=\"relu\", name=\"dense_color_2\")(dense_color_1)\n",
        "    dense_color_3 = layers.Dense(256, activation=\"relu\", name=\"dense_color_3\")(dense_color_2)\n",
        "    dense_color_4 = layers.Dense(128, activation=\"relu\", name=\"dense_color_4\")(dense_color_3)\n",
        "    dense_color_5 = layers.Dense(64, activation=\"relu\", name=\"dense_color_5\")(dense_color_4)\n",
        "    dense_color_6 = layers.Dense(32, activation=\"relu\", name=\"dense_color_6\")(dense_color_5)\n",
        "\n",
        "    # Output layer\n",
        "    output = layers.Dense(num_classes, activation='softmax', name=\"output\")(dense_color_6)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(\n",
        "        inputs=[\n",
        "            rgba_input,\n",
        "            rg_input, rb_input, gb_input, ra_input,\n",
        "            ga_input, ba_input,\n",
        "            rba_input, rga_input, bga_input\n",
        "        ],\n",
        "        outputs=[dense_color_6],\n",
        "        name=\"color_model\"\n",
        "    )\n",
        "    model.name = \"color_model\"\n",
        "    return model\n",
        "\n",
        "out_model = create_parent_model(32, 32, 10)\n",
        "out_model.summary()"
      ],
      "metadata": {
        "id": "BwKRZioLGMun",
        "outputId": "f7428cc7-a4b2-4346-a4e6-e0916ee1f52f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"color_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"color_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ rgba_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ rgba_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ rg_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ gb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ rb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ ra_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ ga_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ ba_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rgba_dense_1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m4,195,328\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rgba_dense_2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ rgba_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ rg_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ gb_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ rb_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ ra_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ ga_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ ba_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color_concatenation       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7168\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ rgba_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ rg_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ gb_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ rb_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ ra_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ ga_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ ba_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7168\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ color_concatenation[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m7,341,056\u001b[0m │ flatten_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m524,800\u001b[0m │ dense_color_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dense_color_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dense_color_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_color_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rba_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rga_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bga_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dense_color_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ rgba_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rgba_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rg_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ra_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ga_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ba_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rgba_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,195,328</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rgba_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ rgba_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ rg_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ gb_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ rb_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ ra_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ ga_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ ba_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color_concatenation       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7168</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rgba_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ rg_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ gb_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ rb_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ ra_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ ga_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ ba_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7168</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ color_concatenation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,341,056</span> │ flatten_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dense_color_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_color_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_color_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_color_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rba_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rga_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bga_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_color_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,172,000\u001b[0m (122.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,172,000</span> (122.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,172,000\u001b[0m (122.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,172,000</span> (122.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "\n",
        "class CIFAR10DataGenerator(Sequence):\n",
        "    def __init__(self, images, labels, image_width, image_height, batch_size=32, num_classes=10, shuffle=True):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.image_width = image_width\n",
        "        self.image_height = image_height\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.images))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_images = self.images[batch_indices]\n",
        "        batch_labels = self.labels[batch_indices]\n",
        "\n",
        "        # Preprocess the batch\n",
        "        inputs = self.preprocess_batch(batch_images)\n",
        "\n",
        "        # One-hot encode labels\n",
        "        batch_labels = to_categorical(batch_labels, num_classes=self.num_classes)\n",
        "\n",
        "        return inputs, batch_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def preprocess_batch(self, batch_images):\n",
        "        # Normalize pixel values to [0, 1]\n",
        "        batch_images = batch_images.astype('float32') / 255.0\n",
        "\n",
        "        # Resize images to (32, 32) if not already\n",
        "        resized = tf.image.resize(batch_images, [self.image_width, self.image_height]).numpy()\n",
        "\n",
        "        # Add Alpha channel (set to 1.0 for full opacity)\n",
        "        alpha_channel = np.ones((resized.shape[0], self.image_width, self.image_height, 1), dtype=np.float32)\n",
        "        rgba = np.concatenate([resized, alpha_channel], axis=-1)  # Shape: (batch_size, 32, 32, 4)\n",
        "\n",
        "        # Create pair inputs (2 channels)\n",
        "        rg = rgba[..., [0, 1]]  # Red + Green\n",
        "        rb = rgba[..., [0, 2]]  # Red + Blue\n",
        "        gb = rgba[..., [1, 2]]  # Green + Blue\n",
        "        ra = rgba[..., [0, 3]]  # Red + Alpha\n",
        "        ga = rgba[..., [1, 3]]  # Green + Alpha\n",
        "        ba = rgba[..., [2, 3]]  # Blue + Alpha\n",
        "\n",
        "        # Create triplet inputs (3 channels)\n",
        "        rba = rgba[..., [0, 2, 3]]  # Red + Blue + Alpha\n",
        "        rga = rgba[..., [0, 1, 3]]  # Red + Green + Alpha\n",
        "        bga = rgba[..., [2, 1, 3]]  # Blue + Green + Alpha\n",
        "\n",
        "        # Organize inputs into a dictionary\n",
        "        inputs = {\n",
        "            \"rgba_input\": rgba,\n",
        "            \"rg_input\": rg,\n",
        "            \"rb_input\": rb,\n",
        "            \"gb_input\": gb,\n",
        "            \"ra_input\": ra,\n",
        "            \"ga_input\": ga,\n",
        "            \"ba_input\": ba,\n",
        "            \"rba_input\": rba,\n",
        "            \"rga_input\": rga,\n",
        "            \"bga_input\": bga\n",
        "        }\n",
        "\n",
        "        # Verification: Print shapes (optional, remove after verification)\n",
        "        # print(\"Batch Shapes:\")\n",
        "        # for key, value in inputs.items():\n",
        "        #     print(f\"{key}: {value.shape}\")\n",
        "\n",
        "        return inputs"
      ],
      "metadata": {
        "id": "SfevyYOc_pXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu3YJtIz62gJ",
        "outputId": "133d44c4-72fd-4d18-d176-db38b3d14259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Inputs Shapes:\n",
            "rgba_input: (50000, 32, 32, 4)\n",
            "rg_input: (50000, 32, 32, 2)\n",
            "rb_input: (50000, 32, 32, 2)\n",
            "gb_input: (50000, 32, 32, 2)\n",
            "ra_input: (50000, 32, 32, 2)\n",
            "ga_input: (50000, 32, 32, 2)\n",
            "ba_input: (50000, 32, 32, 2)\n",
            "rba_input: (50000, 32, 32, 3)\n",
            "rga_input: (50000, 32, 32, 3)\n",
            "bga_input: (50000, 32, 32, 3)\n",
            "\n",
            "Testing Inputs Shapes:\n",
            "rgba_input: (10000, 32, 32, 4)\n",
            "rg_input: (10000, 32, 32, 2)\n",
            "rb_input: (10000, 32, 32, 2)\n",
            "gb_input: (10000, 32, 32, 2)\n",
            "ra_input: (10000, 32, 32, 2)\n",
            "ga_input: (10000, 32, 32, 2)\n",
            "ba_input: (10000, 32, 32, 2)\n",
            "rba_input: (10000, 32, 32, 3)\n",
            "rga_input: (10000, 32, 32, 3)\n",
            "bga_input: (10000, 32, 32, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"color_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"color_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ rgba_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ rgba_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_12 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ rg_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_14 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ gb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ rb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ ra_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_16 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ ga_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_17 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ ba_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rgba_dense_1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m4,195,328\u001b[0m │ flatten_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m2,098,176\u001b[0m │ flatten_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rgba_dense_2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ rgba_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ rg_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ gb_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ rb_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ ra_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ ga_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_dense_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m1,049,600\u001b[0m │ ba_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color_concatenation       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7168\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ rgba_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ rg_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ gb_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ rb_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ ra_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ ga_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ ba_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_21 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7168\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ color_concatenation[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │      \u001b[38;5;34m7,341,056\u001b[0m │ flatten_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m524,800\u001b[0m │ dense_color_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dense_color_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dense_color_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dense_color_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rba_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rga_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bga_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dense_color_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ rgba_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rgba_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rg_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ra_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ga_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ba_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rgba_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,195,328</span> │ flatten_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ flatten_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rgba_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ rgba_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rg_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ rg_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gb_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ gb_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rb_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ rb_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ra_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ ra_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ga_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ ga_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ ba_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ ba_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ color_concatenation       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7168</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rgba_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ rg_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ gb_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ rb_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ ra_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ ga_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ ba_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7168</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ color_concatenation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,341,056</span> │ flatten_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dense_color_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_color_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_color_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_color_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rba_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ rga_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bga_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_color_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_color_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,172,000\u001b[0m (122.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,172,000</span> (122.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,172,000\u001b[0m (122.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,172,000</span> (122.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"ba_dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 2048, but received input with shape (None, 3072)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs={'rgba_input': 'tf.Tensor(shape=(None, 32, 32, 4), dtype=float32)', 'rg_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'rb_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'gb_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'ra_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'ga_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'ba_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'rba_input': 'tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)', 'rga_input': 'tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)', 'bga_input': 'tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)'}\n  • training=True\n  • mask={'rgba_input': 'None', 'rg_input': 'None', 'rb_input': 'None', 'gb_input': 'None', 'ra_input': 'None', 'ga_input': 'None', 'ba_input': 'None', 'rba_input': 'None', 'rga_input': 'None', 'bga_input': 'None'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d90a3a20261d>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m history = parent_model.fit(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 }:\n\u001b[0;32m--> 227\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"ba_dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 2048, but received input with shape (None, 3072)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs={'rgba_input': 'tf.Tensor(shape=(None, 32, 32, 4), dtype=float32)', 'rg_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'rb_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'gb_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'ra_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'ga_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'ba_input': 'tf.Tensor(shape=(None, 32, 32, 2), dtype=float32)', 'rba_input': 'tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)', 'rga_input': 'tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)', 'bga_input': 'tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)'}\n  • training=True\n  • mask={'rgba_input': 'None', 'rg_input': 'None', 'rb_input': 'None', 'gb_input': 'None', 'ra_input': 'None', 'ga_input': 'None', 'ba_input': 'None', 'rba_input': 'None', 'rga_input': 'None', 'bga_input': 'None'}"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "# Define summary writers\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = f'logs_custom/train/{current_time}'\n",
        "val_log_dir = f'logs_custom/val/{current_time}'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "val_summary_writer = tf.summary.create_file_writer(val_log_dir)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Reset metrics\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    val_loss.reset_states()\n",
        "    val_accuracy.reset_states()\n",
        "\n",
        "    # Training\n",
        "    for batch, (inputs, labels) in enumerate(train_generator):\n",
        "        train_step(inputs, labels)\n",
        "\n",
        "        # Optional: Print progress every 100 batches\n",
        "        if batch % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch}, Loss: {train_loss.result():.4f}, Accuracy: {train_accuracy.result():.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    for val_inputs, val_labels in validation_generator:\n",
        "        val_step(val_inputs, val_labels)\n",
        "\n",
        "    # Log metrics to TensorBoard\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
        "\n",
        "    with val_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', val_loss.result(), step=epoch)\n",
        "        tf.summary.scalar('accuracy', val_accuracy.result(), step=epoch)\n",
        "\n",
        "    # Print epoch metrics\n",
        "    template = (\n",
        "        \"Epoch {}/{}\\n\"\n",
        "        \"Train Loss: {:.4f}, Train Accuracy: {:.4f}\\n\"\n",
        "        \"Val Loss: {:.4f}, Val Accuracy: {:.4f}\"\n",
        "    )\n",
        "    print(template.format(\n",
        "        epoch + 1,\n",
        "        epochs,\n",
        "        train_loss.result(),\n",
        "        train_accuracy.result(),\n",
        "        val_loss.result(),\n",
        "        val_accuracy.result()\n",
        "    ))\n",
        "\n",
        "    # Early Stopping and Checkpointing\n",
        "    if val_loss.result() < best_val_loss:\n",
        "        best_val_loss = val_loss.result()\n",
        "        wait = 0\n",
        "        # Save the best model\n",
        "        model.save('best_color_model.h5')\n",
        "        print(\"Model checkpoint saved.\")\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhqAq3ge62gJ"
      },
      "source": [
        "Very practical, right?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CJCWLKS62gK"
      },
      "source": [
        "## What to do once you have a model\n",
        "\n",
        "Once your model architecture is ready, you will want to:\n",
        "\n",
        "- Train your model, evaluate it, and run inference. See our\n",
        "[guide to training & evaluation with the built-in loops](\n",
        "    /guides/training_with_built_in_methods/)\n",
        "- Save your model to disk and restore it. See our\n",
        "[guide to serialization & saving](/guides/serialization_and_saving/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhAW4Jqi62gK"
      },
      "source": [
        "## Feature extraction with a Sequential model\n",
        "\n",
        "Once a Sequential model has been built, it behaves like a\n",
        "[Functional API model](/guides/functional_api/).\n",
        "This means that every layer has an `input`\n",
        "and `output` attribute. These attributes can be used to do neat things, like\n",
        "quickly creating a model that extracts the outputs of all intermediate layers in a\n",
        "Sequential model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1foJivN62gK"
      },
      "outputs": [],
      "source": [
        "initial_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(250, 250, 3)),\n",
        "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "    ]\n",
        ")\n",
        "feature_extractor = keras.Model(\n",
        "    inputs=initial_model.inputs,\n",
        "    outputs=[layer.output for layer in initial_model.layers],\n",
        ")\n",
        "\n",
        "# Call feature extractor on test input.\n",
        "x = ops.ones((1, 250, 250, 3))\n",
        "features = feature_extractor(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGR7jiLL62gK"
      },
      "source": [
        "Here's a similar example that only extract features from one layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsYmoZga62gK"
      },
      "outputs": [],
      "source": [
        "initial_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(250, 250, 3)),\n",
        "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "    ]\n",
        ")\n",
        "feature_extractor = keras.Model(\n",
        "    inputs=initial_model.inputs,\n",
        "    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n",
        ")\n",
        "# Call feature extractor on test input.\n",
        "x = ops.ones((1, 250, 250, 3))\n",
        "features = feature_extractor(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwqXR2L862gM"
      },
      "source": [
        "## Transfer learning with a Sequential model\n",
        "\n",
        "Transfer learning consists of freezing the bottom layers in a model and only training\n",
        "the top layers. If you aren't familiar with it, make sure to read our [guide\n",
        "to transfer learning](/guides/transfer_learning/).\n",
        "\n",
        "Here are two common transfer learning blueprint involving Sequential models.\n",
        "\n",
        "First, let's say that you have a Sequential model, and you want to freeze all\n",
        "layers except the last one. In this case, you would simply iterate over\n",
        "`model.layers` and set `layer.trainable = False` on each layer, except the\n",
        "last one. Like this:\n",
        "\n",
        "```python\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(784)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10),\n",
        "])\n",
        "\n",
        "# Presumably you would want to first load pre-trained weights.\n",
        "model.load_weights(...)\n",
        "\n",
        "# Freeze all layers except the last one.\n",
        "for layer in model.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Recompile and train (this will only update the weights of the last layer).\n",
        "model.compile(...)\n",
        "model.fit(...)\n",
        "```\n",
        "\n",
        "Another common blueprint is to use a Sequential model to stack a pre-trained\n",
        "model and some freshly initialized classification layers. Like this:\n",
        "\n",
        "```python\n",
        "# Load a convolutional base with pre-trained weights\n",
        "base_model = keras.applications.Xception(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    pooling='avg')\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Use a Sequential model to add a trainable classifier on top\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.Dense(1000),\n",
        "])\n",
        "\n",
        "# Compile & train\n",
        "model.compile(...)\n",
        "model.fit(...)\n",
        "```\n",
        "\n",
        "If you do transfer learning, you will probably find yourself frequently using\n",
        "these two patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqmn6aEF62gN"
      },
      "source": [
        "That's about all you need to know about Sequential models!\n",
        "\n",
        "To find out more about building models in Keras, see:\n",
        "\n",
        "- [Guide to the Functional API](/guides/functional_api/)\n",
        "- [Guide to making new Layers & Models via subclassing](/guides/making_new_layers_and_models_via_subclassing/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}